{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "randfaces.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p1oARVh4UVXz"
      },
      "source": [
        "the faces' latent space is created with pbaylies' StyleGAN encoder (building on original work from Puzer): \n",
        "\n",
        "pbaylies repo: https://github.com/pbaylies/stylegan-encoder\n",
        "StyleGAN paper: https://arxiv.org/abs/1812.04948\n",
        "\n",
        "once run as https://colab.research.google.com/github/sifbuilder/eodoes/blob/master/packages/eodoes-do-insights/code/randfaces.ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_iibdCrEzOBs",
        "colab": {}
      },
      "source": [
        "# will define globals\n",
        "\n",
        "cnnid = 'randfaces'\n",
        "\n",
        "autoDownloadImages = 1 # auto run mode - get uri[uri.rfind(\"/\")+1:] files from imgsToAutodownload\n",
        "uploadRawImages = 0 # manually upload raw images\n",
        "takePhotoImages = 0 # take photo for raw images\n",
        "\n",
        "imgsToAutodownload = [\n",
        "  \"https://github.com/sifbuilder/eodoes/raw/master/packages/eodoes-eodo-eofaces/img/amgc.jpg\"\n",
        "]\n",
        "\n",
        "downloadResults = 0 # download results\n",
        "\n",
        "emptyspace = 0 # or reset runtime\n",
        "toSmptyFolders = [\"stylegan-encoder\", \"InterFaceGAN\", \"output_vectors.npy\"]\n",
        "\n",
        "usegdrive = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LIEdgUIv4vRR",
        "colab": {}
      },
      "source": [
        "# process\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import numpy as np\n",
        "import humanize\n",
        "import psutil\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "printm() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YOd4j-8xbCKV",
        "colab": {}
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f7kpW_UWVtao",
        "colab": {}
      },
      "source": [
        "# runtime type must be GPU enabled\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.VERSION\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a8gQ_eCmPFyL",
        "colab": {}
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w5ZDZIDlrqtx",
        "colab": {}
      },
      "source": [
        "# would clean root folder\n",
        "\n",
        "if emptyspace == 1:\n",
        "  print(\"remove folders %s\" %toSmptyFolders)\n",
        "  for folder in toSmptyFolders:\n",
        "    print(\"folder: %s\" %folder)\n",
        "    !rm -r $folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dG872StTLW2w",
        "colab": {}
      },
      "source": [
        "# stylegan folder signature\n",
        "\n",
        "signature='encode_images.py'\n",
        "isExist = os.path.exists(signature)\n",
        "if isExist:\n",
        "  print(\"in stylegan. up to root\")\n",
        "  %cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32c0OfPn5SA_",
        "colab_type": "text"
      },
      "source": [
        "#### pbaylies stylegan model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BkycNxEeUWBA",
        "colab": {}
      },
      "source": [
        "# clone pbaylies stylegan encoder:\n",
        "\n",
        "path = 'stylegan-encoder'\n",
        "isExist = os.path.exists(path)\n",
        "if not isExist:\n",
        "  print(\"stylegan-encoder does not exist. will clone\")\n",
        "  !git clone https://github.com/pbaylies/stylegan-encoder\n",
        "else:\n",
        "  print(\"stylegan-encoder already exists. will not clone\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F-L8CaC6O6Bv",
        "colab": {}
      },
      "source": [
        "# cd into the encoder repo folder, then create image folders\n",
        "\n",
        "if os.path.exists('stylegan-encoder') is True:\n",
        "    os.chdir('stylegan-encoder')\n",
        "if os.path.exists('aligned_images') is False:\n",
        "    os.mkdir('aligned_images')\n",
        "if os.path.exists('raw_images') is False:\n",
        "    os.mkdir('raw_images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RV4LOwC0cl3Q",
        "colab": {}
      },
      "source": [
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import config\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "tflib.init_tf()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS_gx4MY5hB8",
        "colab_type": "text"
      },
      "source": [
        "#### pretrained encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DVdh8LIdQVSz",
        "colab": {}
      },
      "source": [
        "# pretrained resnet encoder - take image as input and estimate its latent code\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1aT59NFy9-bNyXjDuZOTMl0qX0jmZc6Zb\n",
        "!mkdir -p data\n",
        "!mv finetuned_resnet.h5 data\n",
        "!rm -rf generated_images latent_representations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k1WKZNN3vFVv",
        "colab": {}
      },
      "source": [
        "print(\"aligned_images contains %d images ready for encoding!\" %len(os.listdir('aligned_images/')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVEAH_Kl5b1d",
        "colab_type": "text"
      },
      "source": [
        "#### nvidia trained network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1I698RTZoinF",
        "colab": {}
      },
      "source": [
        "# download the StyleGAN network from NVIDIA trained on faces \n",
        "# karras2019stylegan-ffhq-1024x1024.pkl\n",
        "!gdown https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cvOf9x6_rIHO",
        "colab": {}
      },
      "source": [
        "# load the stylegan and instantiate the generator\n",
        "\n",
        "fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "\n",
        "# bsize = 8\n",
        "bsize = 1\n",
        "synthesis_kwargs = dict(output_transform=fmt, minibatch_size=bsize) \n",
        "\n",
        "model_dir = './'\n",
        "model_path = 'karras2019stylegan-ffhq-1024x1024.pkl'\n",
        "print(\"Loading StyleGAN model from %s...\" %model_path)\n",
        "\n",
        "with dnnlib.util.open_url(model_path) as f:\n",
        "  generator_network, discriminator_network, averaged_generator_network = pickle.load(f)\n",
        "  _G = generator_network\n",
        "  _D = discriminator_network\n",
        "  Gs = averaged_generator_network\n",
        "  \n",
        "print(\"StyleGAN loaded\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yxT1eTTxva8k",
        "colab": {}
      },
      "source": [
        "# generator_network.print_layers() # show generator model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igatCMqlhj1s",
        "colab_type": "text"
      },
      "source": [
        "### generate_images(generator, latents)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uaSENEp8efOI",
        "colab": {}
      },
      "source": [
        "# generate and plot random images\n",
        "\n",
        "\n",
        "\n",
        "def generate_images(generator, latent_vector, z = True):\n",
        "  latent_dim = 512\n",
        "  batch_size = latent_vector.shape[0]\n",
        "  \n",
        "  if z: #Start from z: run the full generator network\n",
        "    latents = latent_vector.reshape((batch_size, latent_dim))\n",
        "    return generator.run(latents, None, randomize_noise=True, **synthesis_kwargs)\n",
        "  else: #Start from w: skip the mapping network\n",
        "    latents = latent_vector.reshape((batch_size, 18, latent_dim))\n",
        "    return generator.components.synthesis.run(latents, randomize_noise=True, **synthesis_kwargs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYOrReGaxW4G",
        "colab_type": "text"
      },
      "source": [
        "### plot_images (Gs) ... generate_images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmNixIlbxTrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_imgs(model, rows, columns):\n",
        "  rndvects = {}\n",
        "  for i in range(rows):\n",
        "    f, axarr = plt.subplots(1, columns, figsize = (10, 8))\n",
        "\n",
        "    for j in range(columns):\n",
        "\n",
        "      latent_dim = 512\n",
        "      rndvects[i,j] = np.random.randn(1, latent_dim ) # [[ 0.55756274 ... ]]\n",
        "\n",
        "      latent_vector = rndvects[i,j]\n",
        "      img = generate_images(model, latent_vector, z = True)[0]\n",
        "           \n",
        "      axarr[j].imshow(img)\n",
        "      axarr[j].axis('off')\n",
        "      axarr[j].set_title('Resolution: %s' %str(img.shape))\n",
        "    plt.show()\n",
        "\n",
        "import numpy as np\n",
        "plot_imgs(Gs, 3, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWCLFIlCykmf",
        "colab_type": "text"
      },
      "source": [
        "### show_faves (Gs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ftE6yeqnfAaf",
        "colab": {}
      },
      "source": [
        "fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "\n",
        "def bookmark(latents, new_faves):\n",
        "    for f in new_faves:\n",
        "        faves.append(latents[f])\n",
        "\n",
        "def show_faves(faves):\n",
        "    latents = np.array(faves)\n",
        "    labels = np.zeros([latents.shape[0]] + Gs.input_shapes[1][1:])\n",
        "    n = len(faves)\n",
        "    nr, nc = math.ceil(n / 6), 6\n",
        "    for r in range(nr):\n",
        "\n",
        "        images = Gs.run(latents[6*r:min(n-1, 6*(r+1))], \n",
        "                        None, \n",
        "                        truncation_psi=0.5, \n",
        "                        randomize_noise=False, \n",
        "                        output_transform=fmt)\n",
        "\n",
        "        img1 = np.concatenate([img for img in images], axis=1)\n",
        "        plt.figure(figsize=(24,4))\n",
        "        plt.imshow(img1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_GcjcnNyv9t",
        "colab_type": "text"
      },
      "source": [
        "### get latent interpolations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BukLTheyu_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_latent_interpolation(endpoints, num_frames_per, mode, shuffle):\n",
        "    if shuffle:\n",
        "        random.shuffle(endpoints)\n",
        "    num_endpoints, dim = len(endpoints), len(endpoints[0])\n",
        "    num_frames = num_frames_per * num_endpoints\n",
        "    endpoints = np.array(endpoints)\n",
        "    latents = np.zeros((num_frames, dim))\n",
        "    for e in range(num_endpoints):\n",
        "        e1, e2 = e, (e+1)%num_endpoints\n",
        "        for t in range(num_frames_per):\n",
        "            frame = e * num_frames_per + t\n",
        "            r = 0.5 - 0.5 * np.cos(np.pi*t/(num_frames_per-1)) if mode == 'ease' else float(t) / num_frames_per\n",
        "            latents[frame, :] = (1.0-r) * endpoints[e1,:] + r * endpoints[e2,:]\n",
        "    return latents\n",
        "\n",
        "def get_latent_interpolation_bspline(endpoints, nf, k, s, shuffle):\n",
        "    if shuffle:\n",
        "        random.shuffle(endpoints)\n",
        "    x = np.array(endpoints)\n",
        "    x = np.append(x, x[0,:].reshape(1, x.shape[1]), axis=0)\n",
        "    nd = x.shape[1]\n",
        "    latents = np.zeros((nd, nf))\n",
        "    nss = list(range(1, 10)) + [10]*(nd-19) + list(range(10,0,-1))\n",
        "    for i in tqdm(range(nd-9)):\n",
        "        idx = list(range(i,i+10))\n",
        "        tck, u = interpolate.splprep([x[:,j] for j in range(i,i+10)], k=k, s=s)\n",
        "        out = interpolate.splev(np.linspace(0, 1, num=nf, endpoint=True), tck)\n",
        "        latents[i:i+10,:] += np.array(out)\n",
        "    latents = latents / np.array(nss).reshape((512,1))\n",
        "    return latents.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSrAka93yUf5",
        "colab_type": "text"
      },
      "source": [
        "### gen_imgs (Gs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W6LMdnDyS8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "\n",
        "def gen_imgs(latents, labels):\n",
        "  batch_size = 8\n",
        "  num_frames = latents.shape[0]\n",
        "  num_batches = int(np.ceil(num_frames/batch_size))\n",
        "  images = []\n",
        "  for b in tqdm(range(num_batches)):\n",
        "\n",
        "    latent_vector = latents[b*batch_size:min((b+1)*batch_size, num_frames-1), :]\n",
        "    new_images = Gs.run(latent_vector, \n",
        "                        None, \n",
        "                        truncation_psi=truncation, \n",
        "                        randomize_noise=False, \n",
        "                        output_transform=fmt)\n",
        "\n",
        "    for img in new_images:\n",
        "      images.append(img)\n",
        "  return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5LpSgIfjdxk",
        "colab_type": "text"
      },
      "source": [
        "### make_movie ... gen_imgs (Gs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAx7VpWSje-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_movie(images, out_dir, out_name):\n",
        "    temp_dir = 'frames%06d'%int(1000000*random.random())\n",
        "    os.system('mkdir %s'%temp_dir)\n",
        "    for idx in tqdm(range(len(images))):\n",
        "        PIL.Image.fromarray(images[idx], 'RGB').save('%s/frame%05d.png' % (temp_dir, idx))\n",
        "    cmd = 'ffmpeg -i %s/frame%%05d.png -c:v libx264 -pix_fmt yuv420p %s/%s.mp4' % (temp_dir, out_dir, out_name)\n",
        "    print(cmd)\n",
        "    os.system(cmd)\n",
        "    os.system('rm -rf %s'%temp_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zmSQge3wktM",
        "colab_type": "text"
      },
      "source": [
        "### random_sample (Gs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8lCU-_ykfUGv",
        "colab": {}
      },
      "source": [
        "fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "\n",
        "truncation = 0.5 # default truncation_psi\n",
        "\n",
        "# def random_sample(num_images, scale):\n",
        "#     latents = np.random.RandomState(int(1000*random.random())).randn(num_images, *Gs.input_shapes[0][1:])\n",
        "#     labels = np.zeros([latents.shape[0]] + Gs.input_shapes[1][1:])\n",
        "#     images = Gs.run(latents, None, truncation_psi=truncation, randomize_noise=False, output_transform=fmt)\n",
        "#     images_ct = np.concatenate([img for img in images], axis=1)\n",
        "#     plt.figure(figsize=(scale*num_images, scale))\n",
        "#     plt.imshow(images_ct)\n",
        "#     return images, latents\n",
        "    \n",
        "def random_sample(num_images, scale):\n",
        "  latents = np.random.RandomState(int(1000*random.random())).randn(num_images, *Gs.input_shapes[0][1:])\n",
        "  labels = np.zeros([latents.shape[0]] + Gs.input_shapes[1][1:])\n",
        "\n",
        "  images = Gs.run(latents, \n",
        "                  None, \n",
        "                  truncation_psi=truncation, \n",
        "                  randomize_noise=False, \n",
        "                  output_transform=fmt)\n",
        "\n",
        "  images_ct = np.concatenate([img for img in images], axis=1)\n",
        "  plt.figure(figsize=(scale*num_images, scale))\n",
        "  plt.imshow(images_ct)\n",
        "  plt.axis('off')\n",
        "  plt.savefig('download.png')\n",
        "  return images, latents\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZihYb_d9wSh3",
        "colab_type": "text"
      },
      "source": [
        "### create_image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjEsdREuwQZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/pearsonkyle/Artificial-Art/blob/master/animated_mosaic.py\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def create_image(gen_imgs, name, xsize=4, ysize=4):\n",
        "    fig, axs = plt.subplots(xsize, ysize, figsize=(xsize*2,ysize*2))\n",
        "    plt.subplots_adjust(left=0.05,bottom=0.05,right=0.95,top=0.95, wspace=0.2, hspace=0.2)\n",
        "\n",
        "    cnt = 0\n",
        "    for i in range(ysize):\n",
        "        for j in range(xsize):\n",
        "            imgs = gen_imgs[cnt]\n",
        "            axs[i,j].imshow(imgs)\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "\n",
        "    fig.savefig(name, facecolor='white' )\n",
        "    \n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTgTENFnuXNv",
        "colab_type": "text"
      },
      "source": [
        "### make video ... gen_imgs ... random_sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sqc47nZifTHd",
        "colab": {}
      },
      "source": [
        "# get latent interpolations, then generate images\n",
        "\n",
        "imgnb = 5 # images in row\n",
        "scale = 2\n",
        "images, latents = random_sample(imgnb, scale)\n",
        "\n",
        "latents = get_latent_interpolation(latents, 30, 'linear', False)\n",
        "labels = np.zeros([latents.shape[0]] + Gs.input_shapes[1][1:])\n",
        "\n",
        "images = gen_imgs(latents, labels)    \n",
        "\n",
        "make_movie(images, '.', 'faves13')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtoriOLLuOSK",
        "colab_type": "text"
      },
      "source": [
        "### display video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HCNO6AaqEcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display videos\n",
        "\n",
        "from moviepy.editor import *\n",
        "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
        "from moviepy.Clip import Clip\n",
        "from IPython.display import display\n",
        "\n",
        "vid_path = './faves13.mp4'\n",
        "print (\"vid_path %s\" %vid_path)\n",
        "clip = VideoFileClip(vid_path)\n",
        "display(clip.ipython_display(height=512, autoplay=1, loop=1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icp3BQWHrXnu",
        "colab_type": "text"
      },
      "source": [
        "### animate mosaic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_3GbOPCrbUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/pearsonkyle/Artificial-Art/blob/master/animated_mosaic.py\n",
        "\n",
        "print(\"cwd\", os.getcwd()) # assume in stylegan-endoder\n",
        "if os.path.exists('out_images') is False:\n",
        "    os.mkdir('out_images')   \n",
        "\n",
        "img_rows = 128\n",
        "img_cols = 128\n",
        "channels = 3\n",
        "latent_dim = 512 # 256\n",
        "name = 'goodsell_256_128'\n",
        "\n",
        "# make sure to load in the correct sized data\n",
        "# dcgan = DCGAN(img_rows, img_cols, channels, latent_dim, name)\n",
        "# dcgan.load_weights(generator_file=\"generator ({})4000.h5\".format(dcgan.name), \n",
        "#                    discriminator_file=\"discriminator ({}).h5\".format(dcgan.name))\n",
        "# predictor = dcgan.generator.predict(img_vector)\n",
        "def predictor(latents):\n",
        "  img_array = generate_images(gs, latents)\n",
        "  return img_array\n",
        "\n",
        "# starting point for every image\n",
        "seed_start = np.random.normal(0, 1, (16, latent_dim))\n",
        "\n",
        "# these parameters will change every time step\n",
        "latentSpeed = np.random.normal(3, 1, (16, latent_dim))\n",
        "vary = np.copy(seed_start)\n",
        "\n",
        "# interpolate on time\n",
        "def interp(s, t, T, v):\n",
        "  return s + np.sin( 2*np.pi*(t/T) * v ) \n",
        "\n",
        "# video settings\n",
        "time = 0\n",
        "fps = 30\n",
        "maxTime = 5 # seconds\n",
        "frameCount = 0\n",
        "\n",
        "while (time <= maxTime):\n",
        "\n",
        "    # for each image\n",
        "    for i in range(len(seed_start)): \n",
        "        \n",
        "      # change the latent variables\n",
        "      for j in range(latent_dim):\n",
        "        s = seed_start[i][j]\n",
        "        v = latentSpeed[i][j]\n",
        "        vary[i][j] = interp(s, time, maxTime, v)\n",
        "        # vary[i][j] = seed_start[i][j] + np.sin( 2*np.pi*(time/maxTime) * latentSpeed[i][j] ) \n",
        "        # print(\"vary i j\", vary[i][j]) # -0.3797196489613839\n",
        "        # vector = generate_images(Gs,  vary[i][j])\n",
        "\n",
        "    # gen_imgs = predictor(vary) # dcgan.generator.predict\n",
        "    gen_imgs = generate_images(Gs, vary) # cannot reshape array of size 4096 into shape (16,512)\n",
        "\n",
        "    create_image(gen_imgs, \"out_images/favimgs_{0:05d}.png\".format(frameCount)  )\n",
        "\n",
        "    frameCount += 1\n",
        "    time += 1./fps\n",
        "\n",
        "# ffmpeg -framerate 30 -i \"galaxy_%05d.png\" -i \"Khruangbin_Friday Morning.mp3\" -map 0:v:0 -map 1:a:0 -shortest -c:v libx264 -pix_fmt yuv420p -strict -2 galaxy.mp4 \n",
        "# ffmpeg -framerate 30 -i \"nebula_%05d.png\" -i \"planet_caravan.mp3\" -map 0:v:0 -map 1:a:0 -c:v libx264 -pix_fmt yuv420p nebula.mp4\n",
        "# ffmpeg -framerate 30 -i \"fluidart_%05d.png\" -c:v libx264 -pix_fmt yuv420p fluidart.mp4    \n",
        "\n",
        "# ffmpeg -i frames953417/frame%05d.png -c:v libx264 -pix_fmt yuv420p ./faves13.mp4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uQMX6jGWeWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from moviepy.editor import *\n",
        "import cv2\n",
        "\n",
        "out_path = 'output_videos/'\n",
        "os.makedirs(out_path, exist_ok=True)\n",
        "\n",
        "image_folder = \"out_images/\"\n",
        "print (\"images folder %s\" %image_folder)\n",
        "video_fps = 30.\n",
        "\n",
        "\n",
        "images = [img_path for img_path in sorted(os.listdir(image_folder)) if '.png' in img_path]\n",
        "os.makedirs(out_path, exist_ok=True)\n",
        "\n",
        "prev_id = None\n",
        "img_sets = []\n",
        "for img_path in images:\n",
        "  img_id = img_path.split('_')[0]\n",
        "  if img_id == prev_id: #append\n",
        "    img_sets[-1].append(img_path)\n",
        "    \n",
        "  else: #start a new img set\n",
        "    img_sets.append([])\n",
        "    img_sets[-1].append(img_path)\n",
        "  prev_id = img_id\n",
        "\n",
        "print(\"Found %d image sets!\\n\" %len(img_sets))\n",
        "if image_folder[-1] != '/':\n",
        "  image_folder += '/'\n",
        " \n",
        "\n",
        "# make video per latent direction\n",
        "for i in range(len(img_sets)):\n",
        "  print(\"Generating video %d...\" %i)\n",
        "  set_images = []\n",
        "  vid_name = out_path + 'out_video_%02d' %(i)\n",
        "  print(\"make video: %s\" %vid_name)\n",
        "  for img_path in img_sets[i]:\n",
        "    img_fullpath = image_folder + img_path\n",
        "\n",
        "    frame = cv2.imread(img_fullpath)\n",
        "    set_images.append(frame)\n",
        "\n",
        "  set_images.extend(reversed(set_images))\n",
        "  make_movie(set_images, \".\", vid_name)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-Ju9wSboPZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vids = sorted([f for f in os.listdir('output_videos')])\n",
        "print (\"vids %s\" %vids)\n",
        "for i, vid_name in enumerate(vids):\n",
        "  vid_path = 'output_videos/%s' %vid_name\n",
        "  print (\"vid_path %s\" %vid_path)\n",
        "  clip = VideoFileClip(vid_path)\n",
        "  display(clip.ipython_display(height=512, autoplay=1, loop=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_wXTja0oS5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, vid_name in enumerate(vids):\n",
        "  vid_path = 'output_videos/%s' %vid_name  \n",
        "  print(\"vid_path: %s\" %vid_path)  \n",
        "  files.download(vid_path) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}