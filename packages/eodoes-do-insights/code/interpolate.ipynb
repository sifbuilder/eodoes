{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "interpolate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p1oARVh4UVXz"
      },
      "source": [
        "#### the faces' latent space is created with pbaylies' StyleGAN encoder (building on original work from Puzer): \n",
        "\n",
        "pbaylies repo: https://github.com/pbaylies/stylegan-encoder\n",
        "StyleGAN paper: https://arxiv.org/abs/1812.04948\n",
        "\n",
        "#### the latent space can then be navigated with tr1pzz's fork of the original ShenYujun's InterFaceGAN\n",
        "\n",
        "Original Repo: https://github.com/ShenYujun/InterFaceGAN \n",
        "Paper: https://arxiv.org/abs/1907.10786\n",
        "\n",
        "\n",
        "https://colab.research.google.com/github/iyaja/stylegan-encoder/blob/master/generate_GoT_characters_with_StyleGAN.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4SoPZqIiFzF",
        "colab_type": "text"
      },
      "source": [
        "# context"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iibdCrEzOBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GLOBALS\n",
        "\n",
        "\n",
        "autoDownloadImages = 0 # auto run mode - get uri[uri.rfind(\"/\")+1:] files from imgsToAutodownload\n",
        "uploadRawImages = 0 # manually upload raw images\n",
        "takePhotoImages = 0 # take photo for raw images\n",
        "photosInDrive = 0 # get photos from drive\n",
        "pictsInEncoder = 1 # assume images in folder\n",
        "\n",
        "imgsToAutodownload = [\n",
        "  \"https://github.com/sifbuilder/eodoes/raw/master/packages/eodoes-eodo-eofaces/img/amgc.jpg\",\n",
        "  \"https://github.com/sifbuilder/eodoes/raw/master/packages/eodoes-eodo-eofaces/img/amgf.jpg\"\n",
        "]\n",
        "\n",
        "downloadResults = 0 # download results\n",
        "\n",
        "emptyspace = 0 # or reset runtime\n",
        "toSmptyFolders = [\"stylegan-encoder\", \"InterFaceGAN\", \"output_vectors.npy\"]\n",
        "\n",
        "usegdrive = 0 # would mount gdrive\n",
        "displayInVideo = 1 # would scape video output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3LJEwEdZJyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# would mount gdrive\n",
        "\n",
        "if usegdrive == 1:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "\n",
        "  # https://medium.com/@prajwal.prashanth22/google-colab-drive-as-persistent-storage-for-long-training-runs-cb82bc1d5b71\n",
        "  from keras.callbacks import *\n",
        "  filepath = \"/content/gdrive/My Drive/\" + cnnid + \"/epochs:{epoch:03d}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "  callbacks_list = [checkpoint]\n",
        "  \n",
        "  # referring to callbacks_list when calling model.fit\n",
        "  # model.fit_generator(datagen.flow(x_train, y_train, batch_size=64),\n",
        "  #                   epochs=epochs,\n",
        "  #                   verbose=1,\n",
        "  #                   validation_data=(x_test, y_test),\n",
        "  #                   callbacks=callbacks_list)\n",
        "  \n",
        "  # to resume run model.load_weights at 47th epoch having reached max validation accuracy of 90.5% :\n",
        "  # epoch = 47\n",
        "  # acc = 0.905\n",
        "  # model.load_weights(\"/content/gdrive/My Drive/\" + cnnid + \"/epochs:\" + epoch + \"-val_acc:\" + acc + \".hdf5\")\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LIEdgUIv4vRR",
        "colab": {}
      },
      "source": [
        "# requirements\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import humanize\n",
        "import psutil\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "printm() \n",
        "\n",
        "\n",
        "# runtime type must be GPU enabled\n",
        "import tensorflow as tf\n",
        "tf.VERSION\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "\n",
        "import pickle\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG872StTLW2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# file system context\n",
        "\n",
        "# stylegan folder signature\n",
        "\n",
        "stylegansign = 'encode_images.py'\n",
        "isExist = os.path.exists(stylegansign)\n",
        "if isExist:\n",
        "  print(\"in stylegan. up to root\")\n",
        "  %cd ..  \n",
        "  \n",
        "  \n",
        "# InterFaceGAN folder signature\n",
        "\n",
        "interfacegansign = 'edit.py'\n",
        "isExist = os.path.exists(interfacegansign)\n",
        "if isExist:\n",
        "  print(\"in InterFaceGAN. up to root\")\n",
        "  %cd ..  \n",
        "  \n",
        "!pwd  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "000Z7m8GVqMv",
        "colab_type": "text"
      },
      "source": [
        "#  encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BkycNxEeUWBA",
        "colab": {}
      },
      "source": [
        "# Clone pbaylies' stylegan encoder\n",
        "\n",
        "\n",
        "path = 'stylegan-encoder'\n",
        "isExist = os.path.exists(path)\n",
        "if not isExist:\n",
        "  print(\"stylegan-encoder does not exist. will clone\")\n",
        "  !git clone https://github.com/pbaylies/stylegan-encoder\n",
        "else:\n",
        "  print(\"stylegan-encoder already exists. will not clone\")\n",
        "  \n",
        "# cd into the encoder repo folder  \n",
        "import os\n",
        "os.chdir(\"stylegan-encoder\")  \n",
        "\n",
        "\n",
        "if os.path.exists('aligned_images') is False:\n",
        "    os.mkdir('aligned_images')\n",
        "    \n",
        "if os.path.exists('raw_images') is False:\n",
        "    os.mkdir('raw_images')\n",
        "    \n",
        "if os.path.exists('generated_images') is False:\n",
        "    os.mkdir('generated_images')\n",
        "    \n",
        "if os.path.exists('cache') is False:\n",
        "    os.mkdir('cache')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W9fkViOXMWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# move to stylegan folder\n",
        "\n",
        "if os.path.exists('stylegan-encoder') is True:\n",
        "    os.chdir('stylegan-encoder')\n",
        "\n",
        "!pwd    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIjUze8eXQhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download a pretrained resnet encoder: takes an image as input and estimates its latent code\n",
        "\n",
        "path = 'finetuned_resnet.h5'\n",
        "isExist = os.path.exists(path)\n",
        "if not isExist:\n",
        "  !gdown https://drive.google.com/uc?id=1aT59NFy9-bNyXjDuZOTMl0qX0jmZc6Zb\n",
        "  !mkdir -p data\n",
        "  !cp finetuned_resnet.h5 data\n",
        "else:\n",
        "  print(\"finetuned_resnet already exists. will not gdown it\")  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThcFvzEQV7HQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dnnlib\n",
        "\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "\n",
        "# from encoder.generator_model import Generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wEkL_Zqaufcf"
      },
      "source": [
        "# images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u9PsBGN6Mcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p raw_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2UWcTOGYETf",
        "colab_type": "text"
      },
      "source": [
        "## upload"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Am904hMfc-ug",
        "colab": {}
      },
      "source": [
        "# Opt 1: get the images from the imgsToAutodownload global array set above \n",
        "if autoDownloadImages == 1:\n",
        "  for uri in imgsToAutodownload:\n",
        "    print(\"uri: %s\" %uri)\n",
        "    !wget $uri\n",
        "    fname=uri[uri.rfind(\"/\")+1:]\n",
        "    print(\"fname: %s\" %fname)            \n",
        "    !mv $fname raw_images/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O-XUgE3FTeMK",
        "colab": {}
      },
      "source": [
        "# Opt 2: upload images from the file system\n",
        "if uploadRawImages == 1:\n",
        "  print(\"upload raw images and move to raw_images\")\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  for fname in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fname, length=len(uploaded[fname])))\n",
        "    !mv $fname 'raw_images/'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZU_R54n2_qYr",
        "colab": {}
      },
      "source": [
        "# Opt 3: take image from the web cam\n",
        "if takePhotoImages == 1:\n",
        "  from base64 import b64decode\n",
        "  from IPython.display import HTML, Audio\n",
        "  from google.colab.output import eval_js\n",
        "  from PIL import Image\n",
        "  from datetime import datetime\n",
        "\n",
        "  VIDEO_HTML = \"\"\"\n",
        "  <video autoplay\n",
        "   width=%d height=%d style='cursor: pointer;'></video>\n",
        "  <script>\n",
        "\n",
        "  var video = document.querySelector('video')\n",
        "\n",
        "  navigator.mediaDevices.getUserMedia({ video: true })\n",
        "    .then(stream=> video.srcObject = stream)\n",
        "\n",
        "  var data = new Promise(resolve=>{\n",
        "    video.onclick = ()=>{\n",
        "      var canvas = document.createElement('canvas')\n",
        "      var [w,h] = [video.offsetWidth, video.offsetHeight]\n",
        "      canvas.width = w\n",
        "      canvas.height = h\n",
        "      canvas.getContext('2d')\n",
        "            .drawImage(video, 0, 0, w, h)\n",
        "      video.srcObject.getVideoTracks()[0].stop()\n",
        "      video.replaceWith(canvas)\n",
        "      resolve(canvas.toDataURL('image/jpeg', %f))\n",
        "    }\n",
        "  })\n",
        "  </script>\n",
        "  \"\"\"\n",
        "\n",
        "  def take_photo(quality=1.0, size=(800,600)):\n",
        "    display(HTML(VIDEO_HTML % (size[0],size[1],quality)))\n",
        "    data = eval_js(\"data\")\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    f = io.BytesIO(binary)\n",
        "    img = np.asarray(Image.open(f))\n",
        "\n",
        "    timestampStr = datetime.now().strftime(\"%d-%b-%Y (%H:%M:%S.%f)\")\n",
        "    filename = 'raw_images/photo_%s.jpeg' %timestampStr\n",
        "    Image.fromarray(img).save(filename)\n",
        "    print('Image captured and saved to %s' %filename)\n",
        "\n",
        "  img = take_photo() # click the image to capture a frame!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfUNn-N3YIBp",
        "colab_type": "text"
      },
      "source": [
        "## list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t0hakluVJXvO",
        "colab": {}
      },
      "source": [
        "# List the contents of our image folder:\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "imgs = sorted(os.listdir('raw_images'))\n",
        "\n",
        "print(\"Found %d images in %s\" %(len(imgs), 'raw_images'))\n",
        "if len(imgs) == 0:\n",
        "  print(\"No image found !!!\")\n",
        "else:\n",
        "  print(imgs)\n",
        "\n",
        "  for img_name in imgs:\n",
        "    img_path = 'raw_images/' + img_name\n",
        "    print(\"img_path: %s\" %img_path)\n",
        "    img = Image.open(img_path)\n",
        "    w,h = img.size\n",
        "    rescale_ratio = 256 / min(w,h)\n",
        "    img = img.resize((int(rescale_ratio*w),int(rescale_ratio*h)), Image.LANCZOS)\n",
        "    display(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "de-TddqU_dY-",
        "colab": {}
      },
      "source": [
        "# auto-align faces\n",
        "\n",
        "if pictsInEncoder == 1:\n",
        "  print(\"asume aligned images are there. do not align\")\n",
        "else :\n",
        "  print(\"align images\")\n",
        "  !python align_images.py raw_images/ aligned_images/ --output_size=1048"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M_Er59x8Mt54",
        "colab": {}
      },
      "source": [
        "# display the aligned images\n",
        "from PIL import Image\n",
        "\n",
        "def display_folder_content(folder, res = 256):\n",
        "  if folder[-1] != '/': folder += '/'\n",
        "  for i, img_path in enumerate(sorted(os.listdir(folder))):\n",
        "    if '.png' in img_path:\n",
        "      display(Image.open(folder+img_path).resize((res,res)), 'img %d: %s' %(i, img_path))\n",
        "      print('\\n')\n",
        "      \n",
        "display_folder_content('aligned_images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k1WKZNN3vFVv",
        "colab": {}
      },
      "source": [
        "# show images for encoding \n",
        "\n",
        "print(\"aligned_images contains %d images ready for encoding!\" %len(os.listdir('aligned_images/')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TJoVdu6RZ3vY",
        "colab": {}
      },
      "source": [
        "# clean up the videos-to-generate folder\n",
        "\n",
        "if pictsInEncoder == 1:\n",
        "  print(\"asume videos ok. do not remove\")\n",
        "else :\n",
        "  print(\"remove pre videos\")\n",
        "  !rm -f videos/* "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM1PYury2Hdk",
        "colab_type": "text"
      },
      "source": [
        "# encode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JaAu5s2Z5Ag2",
        "colab": {}
      },
      "source": [
        "# encode aligned images into latent vectors\n",
        "\n",
        "# will remove latent vectors and generated images\n",
        "\n",
        "# will download the StyleGAN network from NVIDIA trained on faces \n",
        "# karras2019stylegan-ffhq-1024x1024.pkl\n",
        "# !gdown https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ\n",
        "\n",
        "# Set the batch size to the number of images in the aligned_images/ folder\n",
        "# If the results don't look great: Play with the encoding arguments!!!\n",
        "# > 1. More iterations             eg.  1000 (def: 200))\n",
        "# > 2. Decrease the L1 penalty to  eg.   0.1 (def: 0.3))\n",
        "# > 3. Lower initial learning rate eg. 0.005 (def: 0.01) \n",
        "#      Decay_rate (def: 0.8)\n",
        "# > 4. Find out about the other encoding options here: \n",
        "# https://github.com/pbaylies/stylegan-encoder/blob/master/encode_images.py \n",
        "\n",
        "\n",
        "if pictsInEncoder == 1:\n",
        "  print(\"asume  generated_images and latent_representation ok. do not encode\")\n",
        "else :  \n",
        "  !rm -rf generated_images  latent_representations\n",
        "  !python encode_images.py \\\n",
        "  --batch_size=2 \\\n",
        "  --output_video=True \\\n",
        "  --load_resnet='data/finetuned_resnet.h5' \\\n",
        "  --lr=0.005 \\\n",
        "  --decay_rate=0.8 \\\n",
        "  --iterations=400 \\\n",
        "  --use_l1_penalty=0.2 \\\n",
        "  --model_url='https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' \\\n",
        "  aligned_images/ generated_images/ latent_representations/\n",
        "\n",
        "  print(\"\\n************ Latent code optimization finished! ***************\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNhW2rZtaVE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if [content]/gdrive, assuming in [content]/stylegan-encoder\n",
        "\n",
        "\n",
        "if pictsInEncoder == 1:\n",
        "  print(\"asume latent vects ok. do not try to get from gdrive\")\n",
        "else: \n",
        "  folder = '../gdrive/My Drive/gdata/'\n",
        "  isExist = os.path.exists(folder)\n",
        "  if isExist:\n",
        "    print ('cp generated_images latent_representations to gdrive')\n",
        "    !cp -r 'generated_images/' folder\n",
        "    !cp -r 'latent_representations/' folder\n",
        "\n",
        "    !ls folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh4qFE-X25yz",
        "colab_type": "text"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBqGVV3Q10e8",
        "colab_type": "text"
      },
      "source": [
        "## model networks (_G, _D, Gs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGTuyMXUfCsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assume in stylegan folder\n",
        "\n",
        "print(\"assume in stylegan folder\")\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSx6SBxYHgdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "\n",
        "print(\"set model networks\")\n",
        "\n",
        "tflib.init_tf()\n",
        "synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, \\\n",
        "                                              nchw_to_nhwc=True), \\\n",
        "                                              minibatch_size=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n-ErZhh9cqUW",
        "colab": {}
      },
      "source": [
        "# load the StyleGAN network - should be in cwd stylegan-encoder\n",
        "#      assumes karras2019stylegan-ffhq-1024x1024.pkl already in cache\n",
        "\n",
        "import pickle\n",
        "\n",
        "model_dir = 'cache/'\n",
        "model_path = [model_dir+f for f in os.listdir(model_dir) if 'stylegan-ffhq' in f][0]\n",
        "print(\"Loading StyleGAN model from %s...\" %model_path)\n",
        "\n",
        "with dnnlib.util.open_url(model_path) as f:\n",
        "  \n",
        "  # generator_network, discriminator_network, averaged_generator_network = pickle.load(f)\n",
        "  _G, _D, Gs = pickle.load(f)\n",
        "  \n",
        "print(\"StyleGAN loaded & ready for sampling!\")\n",
        "\n",
        "# from encoder.generator_model import Generator\n",
        "# generator = Generator(Gs, batch_size=1, randomize_noise=False) \n",
        "  \n",
        "# print(\"generator %s\" %generator)\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYDqxS5c2dCX",
        "colab_type": "text"
      },
      "source": [
        "## image generation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2G6e7l6jzWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# define functions to generate images from latent vectors\n",
        "#    w (latent representation) or z (random image)\n",
        "\n",
        "def gen_images(network, latent_vector, z = True):\n",
        "  \n",
        "  batch_size = latent_vector.shape[0]   \n",
        "  #Start from z: run the full network\n",
        "  if z:\n",
        "    latent_vector = latent_vector.reshape((batch_size, 512))\n",
        "    img_array = network.run( \\\n",
        "                       latent_vector, \\\n",
        "                       None, \\\n",
        "                       randomize_noise=False, \\\n",
        "                       **synthesis_kwargs)\n",
        "  \n",
        "  #Start from w: skip the mapping network\n",
        "  else: \n",
        "    latent_vector = latent_vector.reshape((batch_size, 18, 512))\n",
        "    img_array = network.components.synthesis.run( \\\n",
        "                      latent_vector, \\\n",
        "                      randomize_noise=False, \\\n",
        "                      **synthesis_kwargs)\n",
        "    \n",
        "  return img_array\n",
        "\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBmtsMJucCzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# generator from Generator(Gs, batch_size=1, randomize_noise=False)\n",
        "\n",
        "def generate_image(latent_vector):\n",
        "    latent_vector = latent_vector.reshape((1, 18, 512))\n",
        "    \n",
        "    generator.set_dlatents(latent_vector)    \n",
        "    img_array = generator.generate_images()[0]\n",
        "    \n",
        "    img = PIL.Image.fromarray(img_array, 'RGB')\n",
        "    #return img\n",
        "    return img.resize((256, 256))\n",
        "\n",
        "def move_and_show(latent_vector, direction, coeffs):\n",
        "    print(\"move_and_show\")\n",
        "    fig,ax = plt.subplots(1, len(coeffs), figsize=(15, 10), dpi=80)\n",
        "    for i, coeff in enumerate(coeffs):\n",
        "        new_latent_vector = latent_vector.copy()\n",
        "        new_latent_vector[:8] = (latent_vector + coeff*direction)[:8]\n",
        "        \n",
        "        ax[i].imshow(generate_image(new_latent_vector))\n",
        "        \n",
        "        ax[i].set_title('Coeff: %0.1f' % coeff)\n",
        "    [x.axis('off') for x in ax]\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "def generate_image_for_video(latent_vector):\n",
        "    latent_vector = latent_vector.reshape((1, 18, 512))\n",
        "    \n",
        "    generator.set_dlatents(latent_vector)\n",
        "    img_array = generator.generate_images()[0]\n",
        "    \n",
        "    return img_array\n",
        "  \n",
        "  \n",
        "def move_for_video(latent_vector, direction, coeff):\n",
        "    new_latent_vector = latent_vector.copy()\n",
        "    new_latent_vector[:8] = (latent_vector + coeff*direction)[:8]\n",
        "    \n",
        "    img_array = generate_image(new_latent_vector)\n",
        "    \n",
        "    return img_array  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywwe0jur3SO5",
        "colab_type": "text"
      },
      "source": [
        "# show"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uHRNwnSshG_A",
        "colab": {}
      },
      "source": [
        "# show the encoded images\n",
        "\n",
        "for f in sorted(os.listdir('latent_representations')):\n",
        "  \n",
        "  # gen image from latent vector in latent_representations\n",
        "  w = np.load('latent_representations/' + f).reshape((1,18,-1))\n",
        "  \n",
        "  # use Gs as generator\n",
        "  img = gen_images(Gs, w, z = False)[0]\n",
        "  \n",
        "  plt.imshow(img)\n",
        "  plt.axis('off')\n",
        "  plt.title(\"Generated image from %s\" %f)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ab7zzXNuJMzJ",
        "colab": {}
      },
      "source": [
        "#  show the encoded samples side by side with the original ones:\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_two_images(img1,img2, img_id, fs = 12):\n",
        "  f, axarr = plt.subplots(1,2, figsize=(fs,fs))\n",
        "  axarr[0].imshow(img1)\n",
        "  axarr[0].title.set_text('Encoded img %d' %img_id)\n",
        "  axarr[1].imshow(img2)\n",
        "  axarr[1].title.set_text('Original img %d' %img_id)\n",
        "  plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
        "  plt.show()\n",
        "\n",
        "def display_sbs(folder1, folder2, res = 256):\n",
        "  if folder1[-1] != '/': folder1 += '/'\n",
        "  if folder2[-1] != '/': folder2 += '/'\n",
        "    \n",
        "  imgs1 = sorted([f for f in os.listdir(folder1) if '.png' in f])\n",
        "  imgs2 = sorted([f for f in os.listdir(folder2) if '.png' in f])\n",
        "  if len(imgs1)!=len(imgs2):\n",
        "    print(\"Found different amount of images in aligned vs raw image directories. That's not supposed to happen...\")\n",
        "  \n",
        "  for i in range(len(imgs1)):\n",
        "    img1 = Image.open(folder1+imgs1[i]).resize((res,res))\n",
        "    img2 = Image.open(folder2+imgs2[i]).resize((res,res))\n",
        "    plot_two_images(img1,img2, i)\n",
        "    print(\"\")\n",
        "     \n",
        "display_sbs('generated_images/', 'aligned_images/', res = 512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f8T7mlGN3E3r",
        "colab": {}
      },
      "source": [
        "# list videos\n",
        "\n",
        "videos_dir = 'videos'  \n",
        "videos_dir_bck = 'videos'  \n",
        "\n",
        "!ls $videos_dir\n",
        "\n",
        "thereisbck = os.path.isdir(videos_dir_bck)\n",
        "print(\"thereisbck %s\" %(thereisbck))\n",
        "\n",
        "if thereisbck == True:\n",
        "  print(\"video folders with first names: %s\" %(videos_dir_bck))\n",
        "else:\n",
        "  print(\"copy to bck\")\n",
        "  !cp -r $videos_dir $videos_dir_bck\n",
        "\n",
        "vids = sorted(os.listdir(videos_dir))\n",
        "print(\"Found %d videos in %s\" %(len(vids), videos_dir))\n",
        "for i, vid_fullname in enumerate(vids):\n",
        "  vid_name = vid_fullname.split('.')[0]\n",
        "  vid_ext = vid_fullname.split('.')[1]\n",
        "  newvid_fullname = 'vid_%02d.%s' %(i, vid_ext)\n",
        "  os.rename(videos_dir + '/' + vid_fullname, videos_dir + '/' + newvid_fullname)\n",
        "!ls $videos_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MtLY79VHlDY6",
        "colab": {}
      },
      "source": [
        "# display videos\n",
        "\n",
        "from moviepy.editor import *\n",
        "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
        "from moviepy.Clip import Clip\n",
        "from IPython.display import display\n",
        "\n",
        "if displayInVideo == 1:\n",
        "  videos_dir = 'videos'  \n",
        "  vids = sorted(os.listdir(videos_dir))\n",
        "  for i, vid in enumerate(vids):\n",
        "    vid_path = videos_dir + '/' + vid\n",
        "    print(\"vid %d : %s\" %(i, vid_path))\n",
        "    clip = VideoFileClip(vid_path)\n",
        "    display(clip.ipython_display(height=512, autoplay=1, loop=1))\n",
        "else:\n",
        "  print(\"will not display in notebook videos\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnFzEZaAAyew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "videos_dir = 'videos'  \n",
        "from google.colab import files\n",
        "vids = sorted([f for f in os.listdir(videos_dir)])\n",
        "print(\"vids: %s\" %vids)\n",
        "if downloadResults == 1:\n",
        "  for i, vid_name in enumerate(vids):\n",
        "    vid_path = videos_dir + \"/\" + vid_name  \n",
        "    print(\"vid_path: %s\" %vid_path)  \n",
        "    files.download(vid_path) \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkCWORcakgbs",
        "colab_type": "text"
      },
      "source": [
        "## get good images and select latent vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqnwNs3Ik2UT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assume in encoder\n",
        "\n",
        "print(\"assume in stylegan-encoder\")\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4GTabUrpOwRR",
        "colab": {}
      },
      "source": [
        "# select the good latent images\n",
        "\n",
        "folder = 'latent_representations'\n",
        "\n",
        "good_images = []\n",
        "for i, latents in enumerate(sorted(os.listdir(folder))):\n",
        "  good_images.append(i)\n",
        "\n",
        "# or set good images from list\n",
        "# good_images = [0,1,2,3]  # Uncomment and pick out latents that worked well\n",
        "\n",
        "\n",
        "# save the array of good latent vectors to output_vectors.npy\n",
        "\n",
        "out_file = '../output_vectors.npy'\n",
        "\n",
        "import numpy as np\n",
        "latents = sorted(os.listdir('latent_representations'))\n",
        "\n",
        "final_w_vectors = []\n",
        "for img_id in good_images:\n",
        "  w = np.load('latent_representations/' + latents[img_id])\n",
        "  final_w_vectors.append(w)\n",
        "\n",
        "final_w_vectors = np.array(final_w_vectors)\n",
        "np.save(out_file, final_w_vectors)\n",
        "print(\"%d latent vectors of shape %s saved to %s!\" %(len(good_images), str(w.shape), out_file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VFbpOqW5OelA"
      },
      "source": [
        "# close\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mpbk_0vKgEZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# up to root folder\n",
        "\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bMJGA4K--HCx"
      },
      "source": [
        "# sil"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mIgmKPwzIlJl",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# os.kill(os.getpid(), 9)\n",
        "\n",
        "from numba import cuda\n",
        "cuda.select_device(0)\n",
        "cuda.close()\n",
        "\n",
        "print(\"cpu_ram_total: %s\" %psutil.virtual_memory().total)\n",
        "print(\"cpu_ram_avail: %s\" %psutil.virtual_memory().available)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKTOpoK2AkTl",
        "colab_type": "text"
      },
      "source": [
        "# through latent space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT4BfZqEg5_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if in InterFaceGAN folder, move up\n",
        "\n",
        "import os\n",
        "signature = 'edit.py'\n",
        "\n",
        "doesExist = os.path.exists(signature)\n",
        "if doesExist:\n",
        "  print(\"move up from InterFaceGAN folder\")\n",
        "  os.chdir('../')\n",
        "  \n",
        "print(\"assume in root\")  \n",
        "!pwd && ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G107GNIrRCwO",
        "colab": {}
      },
      "source": [
        "# load from root the array of latent space vectors of shape (18, 512)\n",
        "\n",
        "import numpy as np\n",
        "final_w_vectors = np.load('output_vectors.npy')\n",
        "\n",
        "print(\"%d latent vectors of shape %s loaded from %s!\" %(final_w_vectors.shape[0], str(final_w_vectors.shape[1:]), 'output_vectors.npy'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ei2940NwDoHE",
        "colab": {}
      },
      "source": [
        "# clone InterFaceGAN\n",
        "\n",
        "import os\n",
        "path = 'InterFaceGAN'\n",
        "\n",
        "facegangit = \"https://github.com/ShenYujun/InterFaceGAN.git\"\n",
        "\n",
        "doesExist = os.path.exists(path)\n",
        "if not doesExist:\n",
        "  print(\"InterFaceGAN does not exist. clone %s\" %facegangit)\n",
        "  !git clone $facegangit\n",
        "else:\n",
        "  print(\"InterFaceGAN already exists. will not clone\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3jimeowup6t4",
        "colab": {}
      },
      "source": [
        "# copy latent vectors to InterFaceGAN folder\n",
        "\n",
        "!cp output_vectors.npy InterFaceGAN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LtCgxhF-qWt1",
        "colab": {}
      },
      "source": [
        "# move to InterFaceGAN\n",
        "\n",
        "os.chdir('InterFaceGAN')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VumYqzzx_V-3",
        "colab": {}
      },
      "source": [
        "# download the pretrained StyleGAN FFHQ network from NVIDIA\n",
        "\n",
        "import os\n",
        "path = 'karras2019stylegan-ffhq-1024x1024.pkl'\n",
        "\n",
        "doesExist = os.path.exists(path)\n",
        "if not doesExist:\n",
        "  print(\"Download the pretrained StyleGAN FFHQ network from NVIDIA\")\n",
        "  !gdown https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ\n",
        "else:\n",
        "  print(\"StyleGAN FFHQ exists. will not download\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VXGpXn2rp4VG",
        "colab": {}
      },
      "source": [
        "# copy the pretrained StyleGAN FFHQ network to the models folder\n",
        "\n",
        "!cp karras2019stylegan-ffhq-1024x1024.pkl models/pretrain/karras2019stylegan-ffhq-1024x1024.pkl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jjej2hrzsn1y",
        "colab": {}
      },
      "source": [
        "# convert InterFaceGAN model from to tf to pytorch\n",
        "print (\"convert InterFaceGAN model from to tf to pytorch\")\n",
        "\n",
        "latent_direction = 'age'     #### Pick one of ['age', 'eyeglasses', 'gender', 'pose', 'smile']\n",
        "morph_strength_start = -2    # Controls how strongly we push the face into a certain latent direction (try 1-5)\n",
        "morph_strength_end = 0.1     # Controls how strongly we push the face into a certain latent direction (try 1-5)\n",
        "nr_interpolation_steps = 24  # The amount of intermediate steps/frames to render along the interpolation path\n",
        "\n",
        "boundary_file = 'stylegan_ffhq_%s_w_boundary.npy' %latent_direction\n",
        "resultsPath = \"results/%s\" %latent_direction # eg. results/age\n",
        "print(\"remove %s\" %resultsPath)\n",
        "!rm -r $resultsPath\n",
        "\n",
        "boundary = \"boundaries/stylegan_ffhq_%s_w_boundary.npy\" %latent_direction\n",
        "\n",
        "!python edit.py \\\n",
        "      -m stylegan_ffhq \\\n",
        "      -o $resultsPath \\\n",
        "      -b $boundary \\\n",
        "      -n 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQQ1H97lN43l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate the latent interpolations and output to output_vectors.npy\n",
        "\n",
        "latent_direction = 'age'     #### Pick one of ['age', 'eyeglasses', 'gender', 'pose', 'smile']\n",
        "morph_strength_start = 1    # Controls how strongly we push the face into a certain latent direction (try 1-5)\n",
        "morph_strength_end = -2     # Controls how strongly we push the face into a certain latent direction (try 1-5)\n",
        "nr_interpolation_steps = 24  # The amount of intermediate steps/frames to render along the interpolation path\n",
        "\n",
        "boundary_file = 'stylegan_ffhq_%s_w_boundary.npy' %latent_direction\n",
        "resultsPath = \"results/%s\" %latent_direction # eg. results/age\n",
        "!rm -r $resultsPath\n",
        "\n",
        "boundary = \"boundaries/stylegan_ffhq_%s_w_boundary.npy\" %latent_direction\n",
        "startDistance = \"%.2f\" %morph_strength_start\n",
        "endDistance = \"%.2f\" %morph_strength_end\n",
        "steps = \"%d\" %nr_interpolation_steps\n",
        "\n",
        "outputVectors = 'output_vectors.npy'\n",
        "\n",
        "print(\"generate InterFaceGAN interpolation into %s\" %resultsPath)\n",
        "\n",
        "\n",
        "print(\"resultsPath: %s\" %resultsPath)\n",
        "print(\"latent_direction: %s\" %latent_direction)\n",
        "print(\"boundary: %s\" %boundary)\n",
        "print(\"startDistance: %s\" %startDistance)\n",
        "print(\"endDistance: %s\" %endDistance)\n",
        "print(\"steps: %s\" %steps)\n",
        "\n",
        "!python edit.py \\\n",
        "      -m stylegan_ffhq \\\n",
        "      -b $boundary \\\n",
        "      -s Wp \\\n",
        "      -i $outputVectors \\\n",
        "      -o $resultsPath \\\n",
        "      --start_distance $startDistance \\\n",
        "      --end_distance $endDistance \\\n",
        "      --steps=$steps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LD0oVlmfATur",
        "colab": {}
      },
      "source": [
        "# configure video output\n",
        "\n",
        "out_path = 'output_videos/'\n",
        "\n",
        "image_folder = 'results/%s' %latent_direction\n",
        "print (\"images folder %s\" %image_folder)\n",
        "video_fps = 12."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2pgBNXQ0Tf4k",
        "colab": {}
      },
      "source": [
        "# make the videos per latent direction\n",
        "\n",
        "from moviepy.editor import *\n",
        "import cv2\n",
        "\n",
        "images = [img_path for img_path in sorted(os.listdir(image_folder)) if '.jpg' in img_path]\n",
        "os.makedirs(out_path, exist_ok=True)\n",
        "\n",
        "prev_id = None\n",
        "img_sets = []\n",
        "for img_path in images:\n",
        "  img_id = img_path.split('_')[0]\n",
        "  if img_id == prev_id: #append\n",
        "    img_sets[-1].append(img_path)\n",
        "    \n",
        "  else: #start a new img set\n",
        "    img_sets.append([])\n",
        "    img_sets[-1].append(img_path)\n",
        "  prev_id = img_id\n",
        "\n",
        "print(\"Found %d image sets!\\n\" %len(img_sets))\n",
        "if image_folder[-1] != '/':\n",
        "  image_folder += '/'\n",
        "\n",
        "def make_video(images, vid_name):\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    video = cv2.VideoWriter(vid_name, fourcc, video_fps, (1024, 1024))\n",
        "    gen = {}\n",
        "    for img in images:\n",
        "      video.write(img)\n",
        "    video.release()\n",
        "    print('finished '+ vid_name)  \n",
        "\n",
        "# make video per latent direction\n",
        "for i in range(len(img_sets)):\n",
        "  print(\"Generating video %d...\" %i)\n",
        "  set_images = []\n",
        "  vid_name = out_path + 'out_video_%s_%02d.mp4' %(latent_direction,i)\n",
        "  print(\"make video: %s\" %vid_name)\n",
        "  for img_path in img_sets[i]:\n",
        "    set_images.append(cv2.imread(image_folder + img_path))\n",
        "\n",
        "  set_images.extend(reversed(set_images))\n",
        "  make_video(set_images, vid_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LmRevMq-0lsh",
        "colab": {}
      },
      "source": [
        "# display the resulting videos\n",
        "\n",
        "if displayInVideo == 1:\n",
        "  vids = sorted([f for f in os.listdir('output_videos')])\n",
        "  print (\"vids %s\" %vids)\n",
        "  for i, vid_name in enumerate(vids):\n",
        "    vid_path = 'output_videos/%s' %vid_name\n",
        "    print (\"vid_path %s\" %vid_path)\n",
        "    clip = VideoFileClip(vid_path)\n",
        "    display(clip.ipython_display(height=512, autoplay=1, loop=1))\n",
        "else:\n",
        "  print(\"will not display in-notebook videos - check displayInVideo\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qhNRbqnmTGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# would download the videos\n",
        "\n",
        "from google.colab import files\n",
        "vids = sorted([f for f in os.listdir('output_videos')])\n",
        "if downloadResults == 1:\n",
        "  for i, vid_name in enumerate(vids):\n",
        "    vid_path = 'output_videos/%s' %vid_name  \n",
        "    print(\"vid_path: %s\" %vid_path)  \n",
        "    files.download(vid_path) \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvadKTURzv8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if InterFaceGAN signature, move up to root\n",
        "\n",
        "signature='edit.py'\n",
        "isExist = os.path.exists(signature)\n",
        "if isExist:\n",
        "  print(\"in InterFaceGAN. up to root\")\n",
        "  %cd ..\n",
        "\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0UaT7AUyRBk",
        "colab_type": "text"
      },
      "source": [
        "# interpolate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pACpVbDonjy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# back to stylegan\n",
        "\n",
        "folder = 'stylegan-encoder'\n",
        "isExist = os.path.exists(folder)\n",
        "if isExist:\n",
        "  print(\"cwd to %s\" %folder)\n",
        "  os.chdir(folder)\n",
        "\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T1x0wsa3T-Y",
        "colab_type": "text"
      },
      "source": [
        "## config interpolation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puIoJfVeyP4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load learned latent directions\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "smile_direction = np.load('ffhq_dataset/latent_directions/smile.npy')\n",
        "age_direction = np.load('ffhq_dataset/latent_directions/age.npy')\n",
        "\n",
        "folder = 'latent_representations/'\n",
        "vectors = sorted([f for f in os.listdir(folder)])\n",
        "for i, vector in enumerate(vectors):\n",
        "  vector_path = folder + vector  \n",
        "  print(\"vector: %s\" %vector_path)  \n",
        "\n",
        "    \n",
        "p0 = folder + vectors[0]\n",
        "p1 = folder + vectors[1]\n",
        "\n",
        "v0 = np.load(p0)\n",
        "v1 = np.load(p1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jQraQP_SH2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assume in root, back to the encoder\n",
        "\n",
        "signature='stylegan-encoder'\n",
        "isExist = os.path.exists(signature)\n",
        "if isExist:\n",
        "  print(\"go to stylegan\")\n",
        "  os.chdir('stylegan-encoder')\n",
        "\n",
        "print(\"should be in stylegan-encoder\")\n",
        "!pwd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ2i-lhfzSfL",
        "colab_type": "text"
      },
      "source": [
        "Traits can be adjusted with the move_and_show() function, which takes three arguments: \n",
        "- a latent vector, \n",
        "- a latent direction, and \n",
        "- an array of coefficients. \n",
        "\n",
        "It then performs the following computation:\n",
        "- new latent vector=latent vector+(coefficient∗latent direction)\n",
        "\n",
        "The new latent vectors are passed through the StyleGAN genertor, and the resulting images are plotted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao01MAgupOOY",
        "colab_type": "text"
      },
      "source": [
        "## move and show"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTqTZeuvDKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "\n",
        "# bsize = 8\n",
        "bsize = 1\n",
        "synthesis_kwargs = dict(output_transform=fmt, minibatch_size=bsize) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EANWjFi6NvX3",
        "colab_type": "text"
      },
      "source": [
        "### gen triplet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzJ53rG2nxv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# move_and_show(v0, smile_direction, [-1, 0, 1])\n",
        "\n",
        "ere_latent_vector = v0\n",
        "direction = smile_direction\n",
        "coeffs = [-1, 0, 1]\n",
        "\n",
        "\n",
        "# w = v0.copy()\n",
        "# w = w.reshape((1, 18, 512))\n",
        "# img = gen_images(Gs, w, z = False)[0]\n",
        "\n",
        "# model = Gs\n",
        "\n",
        "print(\"move_and_show\")\n",
        "fig,ax = plt.subplots(1, len(coeffs), figsize=(15, 10), dpi=80)\n",
        "for i, coeff in enumerate(coeffs):\n",
        "\n",
        "  batch_size = 1\n",
        "  latent_vector = ere_latent_vector.copy()\n",
        "  latent_vector = latent_vector.reshape((batch_size, 18, -1))\n",
        "  latent_vector[:8] = (latent_vector + coeff*direction)[:8]\n",
        "\n",
        "  # use Gs as generator\n",
        "  img = gen_images(Gs, latent_vector, z = False)[0]\n",
        "  \n",
        "  ax[i].imshow(img)\n",
        "  ax[i].set_title('Coeff: %0.1f' % coeff)\n",
        "\n",
        "[x.axis('off') for x in ax]\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXcphfPcyPqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# move_and_show(v1, age_direction, [-4, 0, 2])\n",
        "\n",
        "\n",
        "ere_latent_vector = v1\n",
        "direction = age_direction\n",
        "coeffs = [-4, 0, 2]\n",
        "\n",
        "# model = Gs\n",
        "\n",
        "print(\"move_and_show\")\n",
        "fig,ax = plt.subplots(1, len(coeffs), figsize=(15, 10), dpi=80)\n",
        "for i, coeff in enumerate(coeffs):\n",
        "\n",
        "  batch_size = 1\n",
        "  latent_vector = ere_latent_vector.copy()\n",
        "  latent_vector = latent_vector.reshape((batch_size, 18, -1))\n",
        "  latent_vector[:8] = (latent_vector + coeff*direction)[:8]\n",
        "\n",
        "  # use Gs as generator\n",
        "  img = gen_images(Gs, latent_vector, z = False)[0]\n",
        "  \n",
        "  ax[i].imshow(img)\n",
        "  ax[i].set_title('Coeff: %0.1f' % coeff)\n",
        "\n",
        "[x.axis('off') for x in ax]\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OawwrJAUzwkD",
        "colab_type": "text"
      },
      "source": [
        "characters together to find an \"average\" of the two\n",
        " take an average of the two latent vectors and generate an image using the average latent vector.\n",
        " adjust how much of each character you want by changing `alpha`.\n",
        "\n",
        "Now for the moment of truth -- Let's see what the future protector of the realm will look like!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4KX083kyPiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assume defined iter generator\n",
        "\n",
        "alpha = 0.5\n",
        "mix = (((alpha)*v0)+((1-alpha)*v1))\n",
        "# move_and_show(iter, mix, age_direction, [-2, 0, 2])\n",
        "\n",
        "\n",
        "ere_latent_vector = mix\n",
        "direction = age_direction\n",
        "coeffs = [-2, 0, 2]\n",
        "\n",
        "# model = Gs\n",
        "\n",
        "print(\"move_and_show\")\n",
        "fig,ax = plt.subplots(1, len(coeffs), figsize=(15, 10), dpi=80)\n",
        "for i, coeff in enumerate(coeffs):\n",
        "\n",
        "  batch_size = 1\n",
        "  latent_vector = ere_latent_vector.copy()\n",
        "  latent_vector = latent_vector.reshape((batch_size, 18, -1))\n",
        "  latent_vector[:8] = (latent_vector + coeff*direction)[:8]\n",
        "\n",
        "  # use Gs as generator\n",
        "  img = gen_images(Gs, latent_vector, z = False)[0]\n",
        "  \n",
        "  ax[i].imshow(img)\n",
        "  ax[i].set_title('Coeff: %0.1f' % coeff)\n",
        "\n",
        "[x.axis('off') for x in ax]\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zGGdq5iz-nP",
        "colab_type": "text"
      },
      "source": [
        "the new latent character can navigate through age, gender, and smile dimensions\n",
        "\n",
        "fuse characters through Nvidia's style mixing technique. see article. The code below is a modification of Nvidia's style mixing implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlaGhWrbyPez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_style_mixing_figure(png, Gs, w, h, src_dlatents, dst_dlatents, style_ranges):\n",
        "    print(png)\n",
        "    #src_dlatents = Gs.components.mapping.run(src_latents, None) # [seed, layer, component]\n",
        "    #dst_dlatents = Gs.components.mapping.run(dst_latents, None)\n",
        "    src_images = Gs.components.synthesis.run(src_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
        "    dst_images = Gs.components.synthesis.run(dst_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
        "\n",
        "    canvas = PIL.Image.new('RGB', (w * (len(src_dlatents) + 1), h * (len(dst_dlatents) + 1)), 'white')\n",
        "    for col, src_image in enumerate(list(src_images)):\n",
        "        canvas.paste(PIL.Image.fromarray(src_image, 'RGB'), ((col + 1) * w, 0))\n",
        "    for row, dst_image in enumerate(list(dst_images)):\n",
        "        canvas.paste(PIL.Image.fromarray(dst_image, 'RGB'), (0, (row + 1) * h))\n",
        "        row_dlatents = np.stack([dst_dlatents[row]] * len(src_dlatents))\n",
        "        row_dlatents[:, style_ranges[row]] = src_dlatents[:, style_ranges[row]]\n",
        "        row_images = Gs.components.synthesis.run(row_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
        "        for col, image in enumerate(list(row_images)):\n",
        "            canvas.paste(PIL.Image.fromarray(image, 'RGB'), ((col + 1) * w, (row + 1) * h))\n",
        "    canvas.save(png)\n",
        "    return canvas.resize((512,512))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CItPNVIkyPbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tflib.init_tf()\n",
        "synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True), minibatch_size=1)\n",
        "_Gs_cache = dict()\n",
        "\n",
        "# config.result_dir\n",
        "!mkdir -p 'outresults'\n",
        "result_dir = 'outresults'\n",
        "\n",
        "draw_style_mixing_figure(os.path.join(result_dir, 'style-mixing.png'), \\\n",
        "                         Gs, \\\n",
        "                         w=1024, h=1024, src_dlatents=v0.reshape((1, 18, 512)), \\\n",
        "                         dst_dlatents=v1.reshape((1, 18, 512)), \\\n",
        "                         style_ranges=[range(6,14)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaiKMLLu0GeI",
        "colab_type": "text"
      },
      "source": [
        "the simple averaging method seems to produce better results;\n",
        "try Nvidia's style mixing method with different paramets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8OyakOd0bD2",
        "colab_type": "text"
      },
      "source": [
        "Interpolation Videos\n",
        "GAN interpolation videos perform smooth transitions between various images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8CS_frGpoBh",
        "colab_type": "text"
      },
      "source": [
        "### config output video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wxc12240D4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# config video\n",
        "\n",
        "duration_sec = 10.0\n",
        "smoothing_sec = 1.0\n",
        "mp4_fps = 20\n",
        "num_frames = int(np.rint(duration_sec * mp4_fps))\n",
        "\n",
        "\n",
        "# seconds times frames\n",
        "sf = int(duration_sec * mp4_fps)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RREPMAreprI5",
        "colab_type": "text"
      },
      "source": [
        "### generate videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98VQxSWw0Dxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate videos. saved under the reults folder\n",
        "# If you're interpolating between two characters, set these characters here\n",
        "\n",
        "# assume sf defined seconds times frames\n",
        "\n",
        "# v0\n",
        "# v1\n",
        "\n",
        "!mkdir -p 'results'\n",
        "\n",
        "# This creates an nd array that stores all the image frames for cross-character interpolation\n",
        "# src_images = np.stack(generate_image_for_video((0.01*alpha*char2)+((1-(0.01*alpha))*char1)) for alpha in range (100))\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def inter(a, x0 = 0, x1 = 2*np.pi, n = sf):\n",
        "  x = x0 + (x1 - x0 ) * a / n\n",
        "  y = 0.5 * ( 1 + np.cos(x))\n",
        "  return y\n",
        "\n",
        "def a(s,w):\n",
        "  return inter(s) * w\n",
        "def b(s,w):\n",
        "  return (1 - inter(s)) * w\n",
        "\n",
        "def ab(s, w0, w1):\n",
        "  return a(s, w0) + b(s, w1)\n",
        "\n",
        "\n",
        "def generate_image(network, latent_vector, z = True):\n",
        "    img_array = network.components.synthesis.run( \\\n",
        "                      latent_vector, \\\n",
        "                      randomize_noise=False, \\\n",
        "                      **synthesis_kwargs)\n",
        "    return img_array\n",
        "\n",
        "def generate_frame(latent_vector):\n",
        "    new_latent_vector = latent_vector.copy()\n",
        "    new_latent_vector = new_latent_vector.reshape((1, 18, -1))\n",
        "    img = generate_image(Gs, latent_vector, z = False)[0]  \n",
        "    return img\n",
        "  \n",
        "def move_frames(latent_vector, direction, coeff):\n",
        "    new_latent_vector = latent_vector.copy()\n",
        "    new_latent_vector[:8] = (latent_vector + coeff*direction)[:8]\n",
        "    \n",
        "    img_array = generate_frames(new_latent_vector)\n",
        "    \n",
        "    return img_array    \n",
        "  \n",
        "  \n",
        "\n",
        "def tmp(w):\n",
        "  batch_size = 1\n",
        "  latent_vector = w.copy()\n",
        "  latent_vector = latent_vector.reshape((batch_size, 18, -1))\n",
        "  latent_vector[:8] = latent_vector[:8]\n",
        "  img = gen_images(Gs, latent_vector, z = False)[0]\n",
        "  return img  \n",
        "\n",
        "  \n",
        "# This creates an nd array that stores all the image frames for cross-character interpolation\n",
        "# src_images = np.stack(generate_image_for_video((0.01*alpha*char2)+((1-(0.01*alpha))*char1)) for alpha in range (100))\n",
        "# src_images = np.stack(generate_frame(ab(alpha, v0,v1) ) for alpha in range (sf))\n",
        "src_images = np.stack(tmp(ab(alpha,v0,v1)) for alpha in range (sf))\n",
        "\n",
        "  \n",
        "# Uncomment the next line if you want to do a character transforation video, and choose the arguments as per your requirement\n",
        "#src_images = np.stack(move_for_video(dany_meme, smile_direction, (0.02*alpha)) for alpha in range (-100,100))\n",
        "\n",
        "\n",
        "def make_frame(t):\n",
        "    frame_idx = int(np.clip(np.round(t * mp4_fps), 0, num_frames - 1))\n",
        "    src_image = src_images[frame_idx]\n",
        "    return np.array(src_image)\n",
        "\n",
        "# Generate video.\n",
        "import moviepy.editor\n",
        "mp4_file = 'results/interpolate.mp4'\n",
        "mp4_codec = 'libx264'\n",
        "mp4_bitrate = '5M'\n",
        "\n",
        "video_clip = moviepy.editor.VideoClip(make_frame, duration=duration_sec)\n",
        "video_clip.write_videofile(mp4_file, fps=mp4_fps, codec=mp4_codec, bitrate=mp4_bitrate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2Mtjy5jpw8R",
        "colab_type": "text"
      },
      "source": [
        "### display output video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjNTaukgIMcm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display the resulting videos\n",
        "\n",
        "from moviepy.editor import *\n",
        "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
        "from moviepy.Clip import Clip\n",
        "from IPython.display import display\n",
        "\n",
        "vids = sorted([f for f in os.listdir('results')])\n",
        "print (\"vids %s\" %vids)\n",
        "for i, vid_name in enumerate(vids):\n",
        "  vid_path = 'results/%s' %vid_name\n",
        "  print (\"vid_path %s\" %vid_path)\n",
        "  clip = VideoFileClip(vid_path)\n",
        "  display(clip.ipython_display(height=512, autoplay=1, loop=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiC1eykfSnS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}