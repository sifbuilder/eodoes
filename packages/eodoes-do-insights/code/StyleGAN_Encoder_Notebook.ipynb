{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p1oARVh4UVXz"
   },
   "source": [
    "# Part I: Encoding images into StyleGAN's latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKQomSbfVBct"
   },
   "source": [
    "## Before you move on, make sure you have GPU acceleration enabled:\n",
    "> ### Click 'Runtime' in the menu tab at the top\n",
    "> ### Click 'Change runtime type'\n",
    "> ### Make sure the hardware accelerator is set to 'GPU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7kpW_UWVtao"
   },
   "outputs": [],
   "source": [
    "# This is a cell with Python code\n",
    "# Execute the cell by clicking inside it and hitting shift+enter, or by clicking the 'run' button on the left of this cell\n",
    "\n",
    "a = 20\n",
    "b = 30\n",
    "c = a+b\n",
    "print(\"The sum of %d and %d is %d.\" %(a,b,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RVGS1TnvVd35"
   },
   "source": [
    "### Let's first clone the Github repo we'll use: https://github.com/pbaylies/stylegan-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7130,
     "status": "ok",
     "timestamp": 1568375261324,
     "user": {
      "displayName": "Arxiv Insights",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDtLZ4XR7ic9brhw2Q-b7vC2lP5O_wqfoeqNSMYfQ=s64",
      "userId": "09836844893186499683"
     },
     "user_tz": -120
    },
    "id": "BkycNxEeUWBA",
    "outputId": "3a2160d5-0d70-41ce-b388-bcd998ce13dd"
   },
   "outputs": [],
   "source": [
    "!rm -rf sample_data\n",
    "!git clone https://github.com/pbaylies/stylegan-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JN15dzgyVg8D"
   },
   "source": [
    "### cd into the repo folder: (only run this cell once or things might get buggy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6696,
     "status": "ok",
     "timestamp": 1568375261326,
     "user": {
      "displayName": "Arxiv Insights",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDtLZ4XR7ic9brhw2Q-b7vC2lP5O_wqfoeqNSMYfQ=s64",
      "userId": "09836844893186499683"
     },
     "user_tz": -120
    },
    "id": "F-L8CaC6O6Bv",
    "outputId": "e984068a-bb9f-431d-b460-3490b00e8901"
   },
   "outputs": [],
   "source": [
    "cd stylegan-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sv2Pw_1iUKMO"
   },
   "source": [
    "### Let's see the files inside the repo we just cloned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7250,
     "status": "ok",
     "timestamp": 1568375262695,
     "user": {
      "displayName": "Arxiv Insights",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDtLZ4XR7ic9brhw2Q-b7vC2lP5O_wqfoeqNSMYfQ=s64",
      "userId": "09836844893186499683"
     },
     "user_tz": -120
    },
    "id": "glg1mT2aKizL",
    "outputId": "c6dc5816-b791-4beb-e125-1d4eff618415"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gXzIm_TqVk2Q"
   },
   "source": [
    "### Some housekeeping: setting up folder structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOUSJ7TMO6ph"
   },
   "outputs": [],
   "source": [
    "rm -rf aligned_images raw_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5khz8dizO_JB"
   },
   "outputs": [],
   "source": [
    "mkdir -p aligned_images raw_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wEkL_Zqaufcf"
   },
   "source": [
    "# I. Get Images:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wb6eYXL7Pm3S"
   },
   "source": [
    "## Some tips for the images:\n",
    "\n",
    "\n",
    "*   Use HD images (preferably > 1000x1000 pixels)\n",
    "*   Make sure your face is not too small\n",
    "*   Neutral expressions & front facing faces will give better results\n",
    "*   Clear, uniform lighting conditions are also recommened\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qWHBm38POhJ5"
   },
   "source": [
    "## Option 1: Upload Images manually (usually gives the best results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0veUQL2_OoBr"
   },
   "source": [
    "\n",
    "\n",
    "*   Click the '>' icon in the panel on the top left \n",
    "*   Go to the 'Files' tab\n",
    "*   Unfold the stylegan-encoder folder\n",
    "*   Right click the 'stylegan-encoder/raw_images' folder and click \"upload\"\n",
    "*   I'd recommend starting with 3 - 6 different images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ToBlvfPgPedc"
   },
   "source": [
    "## Option 2: Take images using your webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZU_R54n2_qYr"
   },
   "outputs": [],
   "source": [
    "from base64 import b64decode\n",
    "from IPython.display import HTML, Audio\n",
    "from google.colab.output import eval_js\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "VIDEO_HTML = \"\"\"\n",
    "<video autoplay\n",
    " width=%d height=%d style='cursor: pointer;'></video>\n",
    "<script>\n",
    "\n",
    "var video = document.querySelector('video')\n",
    "\n",
    "navigator.mediaDevices.getUserMedia({ video: true })\n",
    "  .then(stream=> video.srcObject = stream)\n",
    "  \n",
    "var data = new Promise(resolve=>{\n",
    "  video.onclick = ()=>{\n",
    "    var canvas = document.createElement('canvas')\n",
    "    var [w,h] = [video.offsetWidth, video.offsetHeight]\n",
    "    canvas.width = w\n",
    "    canvas.height = h\n",
    "    canvas.getContext('2d')\n",
    "          .drawImage(video, 0, 0, w, h)\n",
    "    video.srcObject.getVideoTracks()[0].stop()\n",
    "    video.replaceWith(canvas)\n",
    "    resolve(canvas.toDataURL('image/jpeg', %f))\n",
    "  }\n",
    "})\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "def take_photo(quality=1.0, size=(800,600)):\n",
    "  display(HTML(VIDEO_HTML % (size[0],size[1],quality)))\n",
    "  data = eval_js(\"data\")\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  f = io.BytesIO(binary)\n",
    "  img = np.asarray(Image.open(f))\n",
    "  \n",
    "  timestampStr = datetime.now().strftime(\"%d-%b-%Y (%H:%M:%S.%f)\")\n",
    "  filename = 'raw_images/photo_%s.jpeg' %timestampStr\n",
    "  Image.fromarray(img).save(filename)\n",
    "  print('Image captured and saved to %s' %filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZVBAWK0nMjZd"
   },
   "outputs": [],
   "source": [
    "img = take_photo() # click the image to capture a frame!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7c0sB3grQ0b9"
   },
   "source": [
    "## Let's check the contents of our image folder before we start:\n",
    "#### (You can always manually delete images by right clicking on them in the file tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1568375374738,
     "user": {
      "displayName": "Arxiv Insights",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDtLZ4XR7ic9brhw2Q-b7vC2lP5O_wqfoeqNSMYfQ=s64",
      "userId": "09836844893186499683"
     },
     "user_tz": -120
    },
    "id": "t0hakluVJXvO",
    "outputId": "9e8dbe6a-3d05-4e5b-e69a-952f404e1131"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "imgs = sorted(os.listdir('raw_images'))\n",
    "\n",
    "print(\"Found %d images in %s\" %(len(imgs), 'raw_images'))\n",
    "if len(imgs) == 0:\n",
    "  print(\"Upload images to the \\\"raw_images\\\" folder!\")\n",
    "else:\n",
    "  print(imgs)\n",
    "\n",
    "for img_path in imgs:\n",
    "  img = Image.open('raw_images/' + img_path)\n",
    "  \n",
    "  w,h = img.size\n",
    "  rescale_ratio = 256 / min(w,h)\n",
    "  img = img.resize((int(rescale_ratio*w),int(rescale_ratio*h)), Image.LANCZOS)\n",
    "  display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4MM8TtbwK5w8"
   },
   "source": [
    "# II. Auto-Align faces:\n",
    "### This script wil:\n",
    "\n",
    "\n",
    "1.   Look for faces in the images\n",
    "2.   Crop out the faces from the images\n",
    "3.   Align the faces (center the nose and make the eyes horizontal)\n",
    "4.   Rescale the resulting images and save them in \"aligned_images\" folder\n",
    "\n",
    "### The cell below takes about a minute to run\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28013,
     "status": "ok",
     "timestamp": 1568375405075,
     "user": {
      "displayName": "Arxiv Insights",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDtLZ4XR7ic9brhw2Q-b7vC2lP5O_wqfoeqNSMYfQ=s64",
      "userId": "09836844893186499683"
     },
     "user_tz": -120
    },
    "id": "de-TddqU_dY-",
    "outputId": "0901e91c-3390-4c5e-a27c-f8fb2d872b4f"
   },
   "outputs": [],
   "source": [
    "!python align_images.py raw_images/ aligned_images/ --output_size=1048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gB8kxWpBRSMA"
   },
   "source": [
    "## Let's take a look at our aligned images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 633
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27389,
     "status": "ok",
     "timestamp": 1568375406259,
     "user": {
      "displayName": "Arxiv Insights",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDtLZ4XR7ic9brhw2Q-b7vC2lP5O_wqfoeqNSMYfQ=s64",
      "userId": "09836844893186499683"
     },
     "user_tz": -120
    },
    "id": "M_Er59x8Mt54",
    "outputId": "7ba76c3b-7d34-483f-b65f-88b37c761683"
   },
   "outputs": [],
   "source": [
    "def display_folder_content(folder, res = 256):\n",
    "  if folder[-1] != '/': folder += '/'\n",
    "  for i, img_path in enumerate(sorted(os.listdir(folder))):\n",
    "    if '.png' in img_path:\n",
    "      display(Image.open(folder+img_path).resize((res,res)), 'img %d: %s' %(i, img_path))\n",
    "      print('\\n')\n",
    "      \n",
    "display_folder_content('aligned_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OaEzcVk7RVjI"
   },
   "source": [
    "# Important, before moving on:\n",
    "### Manually clean the 'aligned_images' directory\n",
    "\n",
    "> ### 1. Manually remove all 'bad' images that are not faces / don't look sharp / clear \n",
    "> #####  (Use the image names from the plots above to guide you)\n",
    "> ### 2. Make sure you don't have too many faces in this folder (8 at most preferably)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0mtyFkhHRMU"
   },
   "source": [
    "# Encoding faces into StyleGAN latent space:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLaBRaNjSsZc"
   },
   "source": [
    "## We'll be using pbaylies' awesome encoder repo (building on original work from Puzer): https://github.com/pbaylies/stylegan-encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmHwHBH8QUc7"
   },
   "source": [
    "## First, let's download a pretrained resnet encoder: (see video for what this does)\n",
    "### --> This model takes an image as input and estimates the corresponding latent code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15920,
     "status": "ok",
     "timestamp": 1568375287392,
     "user": {
      "displayName": "Arxiv Insights",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDtLZ4XR7ic9brhw2Q-b7vC2lP5O_wqfoeqNSMYfQ=s64",
      "userId": "09836844893186499683"
     },
     "user_tz": -120
    },
    "id": "DVdh8LIdQVSz",
    "outputId": "75bf9a06-20cf-4fb0-b0f8-60e8052e5662"
   },
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=1aT59NFy9-bNyXjDuZOTMl0qX0jmZc6Zb\n",
    "!mkdir -p data\n",
    "!mv finetuned_resnet.h5 data\n",
    "!rm -rf generated_images latent_representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p3Xjrc2hTmMI"
   },
   "source": [
    "# III. The actual encoding process:\n",
    "> #### Highly recommended: play with the encoding params: they have a huge effect on the latent representations & images!\n",
    "> #### Extra encoding options: https://github.com/pbaylies/stylegan-encoder/blob/master/encode_images.py\n",
    "\n",
    "#### Note: This script will also download:\n",
    "\n",
    "\n",
    "*   The pretrained StyleGAN network from NVIDIA trained on faces\n",
    "*   A pretrained VGG-16 network, trained on ImageNet\n",
    "\n",
    "#### After guessing the initial latent codes using the pretrained ResNet, it will run gradient descent to optimize the latent faces!\n",
    "#### Note that by default, we're optimizing w vectors, not z-vectors!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7318,
     "status": "ok",
     "timestamp": 1568375406260,
     "user": {
      "displayName": "Arxiv Insights",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDtLZ4XR7ic9brhw2Q-b7vC2lP5O_wqfoeqNSMYfQ=s64",
      "userId": "09836844893186499683"
     },
     "user_tz": -120
    },
    "id": "k1WKZNN3vFVv",
    "outputId": "d2d30b19-eca7-4f86-f2ca-0234f2a7270f"
   },
   "outputs": [],
   "source": [
    "print(\"aligned_images contains %d images ready for encoding!\" %len(os.listdir('aligned_images/')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GqiCMtQnZJus"
   },
   "source": [
    "#### For best performance, set the batch_size argument below equal to the number of aligned_images (see previous cell)\n",
    "> Keep batch_size<8 or the GPU might run out of memory (Colab runs on Tesla K80's)\n",
    "\n",
    "### Depending on the settings, the encoding process might take a few minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 374882,
     "status": "ok",
     "timestamp": 1568375781623,
     "user": {
      "displayName": "Arxiv Insights",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDtLZ4XR7ic9brhw2Q-b7vC2lP5O_wqfoeqNSMYfQ=s64",
      "userId": "09836844893186499683"
     },
     "user_tz": -120
    },
    "id": "JaAu5s2Z5Ag2",
    "outputId": "bb8fbe9c-a7a6-4733-d42e-eee9441e519d"
   },
   "outputs": [],
   "source": [
    "!python encode_images.py --batch_size=2 --output_video=True --load_resnet='data/finetuned_resnet.h5' --lr=0.01 --decay_rate=0.8 --iterations=200 --use_l1_penalty=0.3 aligned_images/ generated_images/ latent_representations/\n",
    "print(\"\\n************ Latent code optimization finished! ***************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zsKCGkhjclX_"
   },
   "source": [
    "## Showtime!\n",
    "### Let's load the StyleGAN network into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13794,
     "status": "ok",
     "timestamp": 1568375945417,
     "user": {
      "displayName": "Arxiv Insights",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDtLZ4XR7ic9brhw2Q-b7vC2lP5O_wqfoeqNSMYfQ=s64",
      "userId": "09836844893186499683"
     },
     "user_tz": -120
    },
    "id": "n-ErZhh9cqUW",
    "outputId": "5b0f2ebc-a3d3-4244-ba78-bb4f7bd64b4a"
   },
   "outputs": [],
   "source": [
    "import dnnlib, pickle\n",
    "import dnnlib.tflib as tflib\n",
    "tflib.init_tf()\n",
    "synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True), minibatch_size=1)\n",
    "\n",
    "model_dir = 'cache/'\n",
    "model_path = [model_dir+f for f in os.listdir(model_dir) if 'stylegan-ffhq' in f][0]\n",
    "print(\"Loading StyleGAN model from %s...\" %model_path)\n",
    "\n",
    "with dnnlib.util.open_url(model_path) as f:\n",
    "  generator_network, discriminator_network, averaged_generator_network = pickle.load(f)\n",
    "  \n",
    "print(\"StyleGAN loaded & ready for sampling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9argInqrgIji"
   },
   "outputs": [],
   "source": [
    "def generate_images(generator, latent_vector, z = True):\n",
    "    batch_size = latent_vector.shape[0]\n",
    "    \n",
    "    if z: #Start from z: run the full generator network\n",
    "        return generator.run(latent_vector.reshape((batch_size, 512)), None, randomize_noise=False, **synthesis_kwargs)\n",
    "    else: #Start from w: skip the mapping network\n",
    "        return generator.components.synthesis.run(latent_vector.reshape((batch_size, 18, 512)), randomize_noise=False, **synthesis_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uaSENEp8efOI"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_imgs(model, rows, columns):\n",
    "  for i in range(rows):\n",
    "    f, axarr = plt.subplots(1,columns, figsize = (20,8))\n",
    "    for j in range(columns):\n",
    "      img = generate_images(model, np.random.randn(1,512), z = True)[0]\n",
    "      axarr[j].imshow(img)\n",
    "      axarr[j].axis('off')\n",
    "      axarr[j].set_title('Resolution: %s' %str(img.shape))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yLaJBYEuf09x"
   },
   "source": [
    "## Let's plot some random StyleGAN samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1wYvbdHOOmOt20Z02t38lJyOO5s0b7Zqr"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9523,
     "status": "ok",
     "timestamp": 1568376779655,
     "user": {
      "displayName": "Arxiv Insights",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDtLZ4XR7ic9brhw2Q-b7vC2lP5O_wqfoeqNSMYfQ=s64",
      "userId": "09836844893186499683"
     },
     "user_tz": -120
    },
    "id": "hwwHDl-heh6O",
    "outputId": "d7c51f19-2453-4b38-c854-392aa08bcaaa"
   },
   "outputs": [],
   "source": [
    "plot_imgs(averaged_generator_network, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g1wKMAcvUPoH"
   },
   "source": [
    "# Let's take a look at the results of our encoding:\n",
    "### If the results don't look great: Play with the encoding arguments!!!\n",
    "> 1. Run the optimization for more iterations (eg 1000)\n",
    "> 2. Decrease the L1 penalty (to eg 0.1)\n",
    "> 3. Try a lower initial learning rate (eg 0.005) or play with the decay_rate\n",
    "> 4. Find out about the other encoding options here: https://github.com/pbaylies/stylegan-encoder/blob/master/encode_images.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1805,
     "status": "ok",
     "timestamp": 1568376863930,
     "user": {
      "displayName": "Arxiv Insights",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDtLZ4XR7ic9brhw2Q-b7vC2lP5O_wqfoeqNSMYfQ=s64",
      "userId": "09836844893186499683"
     },
     "user_tz": -120
    },
    "id": "uHRNwnSshG_A",
    "outputId": "ff671dc1-4878-4355-8030-034911e19ddb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for f in sorted(os.listdir('latent_representations')):\n",
    "  w = np.load('latent_representations/' + f).reshape((1,18,-1))\n",
    "  img = generate_images(averaged_generator_network, w, z = False)[0]\n",
    "  plt.imshow(img)\n",
    "  plt.axis('off')\n",
    "  plt.title(\"Generated image from %s\" %f)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cJNqedjdi-MZ"
   },
   "source": [
    "## Let's compare our encoded samples with the original ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 728
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3617,
     "status": "ok",
     "timestamp": 1568376889854,
     "user": {
      "displayName": "Arxiv Insights",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDtLZ4XR7ic9brhw2Q-b7vC2lP5O_wqfoeqNSMYfQ=s64",
      "userId": "09836844893186499683"
     },
     "user_tz": -120
    },
    "id": "Ab7zzXNuJMzJ",
    "outputId": "8df67015-0cd2-4868-b297-67084d103b0f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_two_images(img1,img2, img_id, fs = 12):\n",
    "  f, axarr = plt.subplots(1,2, figsize=(fs,fs))\n",
    "  axarr[0].imshow(img1)\n",
    "  axarr[0].title.set_text('Encoded img %d' %img_id)\n",
    "  axarr[1].imshow(img2)\n",
    "  axarr[1].title.set_text('Original img %d' %img_id)\n",
    "  plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "  plt.show()\n",
    "\n",
    "def display_sbs(folder1, folder2, res = 256):\n",
    "  if folder1[-1] != '/': folder1 += '/'\n",
    "  if folder2[-1] != '/': folder2 += '/'\n",
    "    \n",
    "  imgs1 = sorted([f for f in os.listdir(folder1) if '.png' in f])\n",
    "  imgs2 = sorted([f for f in os.listdir(folder2) if '.png' in f])\n",
    "  if len(imgs1)!=len(imgs2):\n",
    "    print(\"Found different amount of images in aligned vs raw image directories. That's not supposed to happen...\")\n",
    "  \n",
    "  for i in range(len(imgs1)):\n",
    "    img1 = Image.open(folder1+imgs1[i]).resize((res,res))\n",
    "    img2 = Image.open(folder2+imgs2[i]).resize((res,res))\n",
    "    plot_two_images(img1,img2, i)\n",
    "    print(\"\")\n",
    "     \n",
    "display_sbs('generated_images/', 'aligned_images/', res = 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y3GK-0POCP52"
   },
   "source": [
    "### Note: \n",
    "If you want to watch the whole thing unfold for yourself, you can **download the optimization videos** from the \"videos\" folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VFbpOqW5OelA"
   },
   "source": [
    "# IV. Cherry pick images & dump their latent vectors to disk\n",
    "### Manipulating latent vectors is tricky and will only work if the face encoding looks 'good'\n",
    "### Cherry pick a few images where the optimization worked well\n",
    "> (Use the image indices from the plot titles above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OBifaaJ3PKq-"
   },
   "outputs": [],
   "source": [
    "good_images = [0,1]  #Change these numbers to pick out latents that worked well (see the image plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rGj-xKoYX1TZ"
   },
   "source": [
    "## Save these latent vectors to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1281,
     "status": "ok",
     "timestamp": 1568329459284,
     "user": {
      "displayName": "Xander Steenbrugge",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC-K7Te91HTeoiSIz3lowwNpB0vGjt45yqo2ud5=s64",
      "userId": "05420087124506038146"
     },
     "user_tz": -120
    },
    "id": "hKtgwRDPOgrt",
    "outputId": "864c8fb4-d8c4-4e85-e574-0cc10b878ea5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "latents = sorted(os.listdir('latent_representations'))\n",
    "\n",
    "out_file = '/content/output_vectors.npy'\n",
    "\n",
    "final_w_vectors = []\n",
    "for img_id in good_images:\n",
    "  w = np.load('latent_representations/' + latents[img_id])\n",
    "  final_w_vectors.append(w)\n",
    "\n",
    "final_w_vectors = np.array(final_w_vectors)\n",
    "np.save(out_file, final_w_vectors)\n",
    "print(\"%d latent vectors of shape %s saved to %s!\" %(len(good_images), str(w.shape), out_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zODfZSdhX9MM"
   },
   "source": [
    "# V. Manipulating the faces\n",
    "### Everything we downloaded / saved to disk is currently on a temporary VM running on Google Colab\n",
    "### (which can be accessed through another notebook you run)\n",
    "> If you want to reuse the latent vectors later, you can download them manually **(highly recommended!!)** :\n",
    ">> * Go to the root directory using the Files browser\n",
    ">> * Richt-click & Download the latent representations: \"output_vectors.npy\"\n",
    "## Next, let's continue with notebook II:\n",
    "> ### Simply open the second notebook from the Drive folder and continue the guide-steps\n",
    "> ### (Hint: Notebook II is where all the fun is!)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1. StyleGAN_Encoder_Notebook.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
