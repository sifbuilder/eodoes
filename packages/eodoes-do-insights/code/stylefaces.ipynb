{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "stylefaces.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p1oARVh4UVXz"
      },
      "source": [
        "# Style encoding as by Xander Steenbrugge\n",
        "https://www.youtube.com/watch?v=dCKbRCUyop8\n",
        "\n",
        "#### the faces' latent space is created with pbaylies' awesome StyleGAN encoder (building on original work from Puzer): \n",
        "\n",
        "pbaylies repo: https://github.com/pbaylies/stylegan-encoder\n",
        "StyleGAN paper: https://arxiv.org/abs/1812.04948\n",
        "\n",
        "#### the latent space can then be navigated with tr1pzz's fork of the original ShenYujun's InterFaceGAN\n",
        "\n",
        "Original Repo: https://github.com/ShenYujun/InterFaceGAN \n",
        "Paper: https://arxiv.org/abs/1907.10786"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8GQQLV4xfYAJ"
      },
      "source": [
        "## Part I: Encoding images into StyleGAN's latent space\n",
        "\n",
        "Runtime type must be GPU enabled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LIEdgUIv4vRR",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import humanize\n",
        "import psutil\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "printm() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f7kpW_UWVtao",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.VERSION\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YOd4j-8xbCKV",
        "colab": {}
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a8gQ_eCmPFyL",
        "colab": {}
      },
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XCR8cEViTR1o"
      },
      "source": [
        "## config globals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q78b9yb8TNTW",
        "colab": {}
      },
      "source": [
        "autoMode = 1 # auto run mode - get uri[uri.rfind(\"/\")+1:] files from imgsToAutodownload\n",
        "uploadRawImages = 0 # manually upload raw images\n",
        "takePhotoImages = 0 # take photo for raw images\n",
        "\n",
        "imgsToAutodownload = [\n",
        "  \"https://github.com/sifbuilder/eodoes/raw/master/packages/eodoes-eodo-eofaces/img/2019-09-22_19-04-13.jpg\"\n",
        "#  , \"https://github.com/sifbuilder/eodoes/raw/master/packages/eodoes-eodo-eofaces/img/2019-09-22_19-09-43.jpg\"\n",
        "]\n",
        "\n",
        "dodownload = 1 # download results\n",
        "\n",
        "emptyspace = 0 # or reset runtime\n",
        "toSmptyFolders = [\"stylegan-encoder\", \"InterFaceGAN\", \"output_vectors.npy\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5ZDZIDlrqtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if emptyspace == 1:\n",
        "  print(\"remove folders %s\" %toSmptyFolders)\n",
        "  for folder in toSmptyFolders:\n",
        "    print(\"folder: %s\" %folder)\n",
        "    !rm -r $folder\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RVGS1TnvVd35"
      },
      "source": [
        "### Clone pbaylies' stylegan encoder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BkycNxEeUWBA",
        "colab": {}
      },
      "source": [
        "path = 'stylegan-encoder'\n",
        "isExist = os.path.exists(path)\n",
        "if not isExist:\n",
        "  print(\"stylegan-encoder does not exist. will clone\")\n",
        "  !git clone https://github.com/pbaylies/stylegan-encoder\n",
        "else:\n",
        "  print(\"stylegan-encoder already exists. will not clone\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JN15dzgyVg8D"
      },
      "source": [
        "### cd into the encoder repo folder and create image folders:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F-L8CaC6O6Bv",
        "colab": {}
      },
      "source": [
        "cd stylegan-encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5khz8dizO_JB",
        "colab": {}
      },
      "source": [
        "mkdir -p aligned_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vl9qVJrpSyuP",
        "colab": {}
      },
      "source": [
        "mkdir -p raw_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G_jlfXOP6CDQ",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wEkL_Zqaufcf"
      },
      "source": [
        "### Get the images:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wb6eYXL7Pm3S"
      },
      "source": [
        "*   Use HD images (preferably > 1000x1000 pixels)\n",
        "*   Start with 3 - 6 different images\n",
        "*   Make sure faces are not too small\n",
        "*   Neutral expressions & front facing faces will be better\n",
        "*   Clear, uniform lighting conditions are also recommened\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Am904hMfc-ug",
        "colab": {}
      },
      "source": [
        "# Opt 1: get the images from the imgsToAutodownload global array set above \n",
        "if autoMode == 1:\n",
        "  for uri in imgsToAutodownload:\n",
        "    print(\"uri: %s\" %uri)\n",
        "    !wget $uri\n",
        "    fname=uri[uri.rfind(\"/\")+1:]\n",
        "    print(\"fname: %s\" %fname)            \n",
        "    !mv $fname raw_images/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O-XUgE3FTeMK",
        "colab": {}
      },
      "source": [
        "# Opt 2: upload images from the file system\n",
        "if uploadRawImages == 1:\n",
        "  print(\"upload raw images and move to raw_images\")\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  for fname in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fname, length=len(uploaded[fname])))\n",
        "    !mv $fname 'raw_images/'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZU_R54n2_qYr",
        "colab": {}
      },
      "source": [
        "# Opt 3: take image from the web cam\n",
        "if takePhotoImages == 1:\n",
        "  from base64 import b64decode\n",
        "  from IPython.display import HTML, Audio\n",
        "  from google.colab.output import eval_js\n",
        "  from PIL import Image\n",
        "  from datetime import datetime\n",
        "\n",
        "  VIDEO_HTML = \"\"\"\n",
        "  <video autoplay\n",
        "   width=%d height=%d style='cursor: pointer;'></video>\n",
        "  <script>\n",
        "\n",
        "  var video = document.querySelector('video')\n",
        "\n",
        "  navigator.mediaDevices.getUserMedia({ video: true })\n",
        "    .then(stream=> video.srcObject = stream)\n",
        "\n",
        "  var data = new Promise(resolve=>{\n",
        "    video.onclick = ()=>{\n",
        "      var canvas = document.createElement('canvas')\n",
        "      var [w,h] = [video.offsetWidth, video.offsetHeight]\n",
        "      canvas.width = w\n",
        "      canvas.height = h\n",
        "      canvas.getContext('2d')\n",
        "            .drawImage(video, 0, 0, w, h)\n",
        "      video.srcObject.getVideoTracks()[0].stop()\n",
        "      video.replaceWith(canvas)\n",
        "      resolve(canvas.toDataURL('image/jpeg', %f))\n",
        "    }\n",
        "  })\n",
        "  </script>\n",
        "  \"\"\"\n",
        "\n",
        "  def take_photo(quality=1.0, size=(800,600)):\n",
        "    display(HTML(VIDEO_HTML % (size[0],size[1],quality)))\n",
        "    data = eval_js(\"data\")\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    f = io.BytesIO(binary)\n",
        "    img = np.asarray(Image.open(f))\n",
        "\n",
        "    timestampStr = datetime.now().strftime(\"%d-%b-%Y (%H:%M:%S.%f)\")\n",
        "    filename = 'raw_images/photo_%s.jpeg' %timestampStr\n",
        "    Image.fromarray(img).save(filename)\n",
        "    print('Image captured and saved to %s' %filename)\n",
        "\n",
        "  img = take_photo() # click the image to capture a frame!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7c0sB3grQ0b9"
      },
      "source": [
        "### List the contents of our image folder:\n",
        "images can be deleted by right clicking on them in the file tab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t0hakluVJXvO",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "imgs = sorted(os.listdir('raw_images'))\n",
        "\n",
        "print(\"Found %d images in %s\" %(len(imgs), 'raw_images'))\n",
        "if len(imgs) == 0:\n",
        "  print(\"No image found !!!\")\n",
        "else:\n",
        "  print(imgs)\n",
        "\n",
        "  for img_name in imgs:\n",
        "    img_path = 'raw_images/' + img_name\n",
        "    print(\"img_path: %s\" %img_path)\n",
        "    img = Image.open(img_path)\n",
        "    w,h = img.size\n",
        "    rescale_ratio = 256 / min(w,h)\n",
        "    img = img.resize((int(rescale_ratio*w),int(rescale_ratio*h)), Image.LANCZOS)\n",
        "    display(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4MM8TtbwK5w8"
      },
      "source": [
        "### auto-align faces:\n",
        "1.   Look for faces in the images\n",
        "2.   Crop out the faces from the images\n",
        "3.   Align the faces (center the nose and make the eyes horizontal)\n",
        "4.   Rescale the resulting images and save them in \"aligned_images\" folder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "de-TddqU_dY-",
        "colab": {}
      },
      "source": [
        "!python align_images.py raw_images/ aligned_images/ --output_size=1048"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gB8kxWpBRSMA"
      },
      "source": [
        "### display the aligned images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M_Er59x8Mt54",
        "colab": {}
      },
      "source": [
        "def display_folder_content(folder, res = 256):\n",
        "  if folder[-1] != '/': folder += '/'\n",
        "  for i, img_path in enumerate(sorted(os.listdir(folder))):\n",
        "    if '.png' in img_path:\n",
        "      display(Image.open(folder+img_path).resize((res,res)), 'img %d: %s' %(i, img_path))\n",
        "      print('\\n')\n",
        "      \n",
        "display_folder_content('aligned_images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OaEzcVk7RVjI"
      },
      "source": [
        "### Manually clean the 'aligned_images' directory\n",
        "\n",
        "> #### 1. Manually remove all 'bad' images that do not look sharp or clear \n",
        "> #### 2. Make sure not to have too many faces (preferably 8 max)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kmHwHBH8QUc7"
      },
      "source": [
        "### Download a pretrained resnet encoder: (see video for what this does)\n",
        "### --> This model takes an image as input and estimates the corresponding latent code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DVdh8LIdQVSz",
        "colab": {}
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1aT59NFy9-bNyXjDuZOTMl0qX0jmZc6Zb\n",
        "!mkdir -p data\n",
        "!mv finetuned_resnet.h5 data\n",
        "!rm -rf generated_images latent_representations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p3Xjrc2hTmMI"
      },
      "source": [
        "### encode the images\n",
        "(adapt the encoding params: they determine the latent representations & images!)\n",
        "see extra encoding options: https://github.com/pbaylies/stylegan-encoder/blob/master/encode_images.py\n",
        "\n",
        "Note: This script will also download:\n",
        "*   The pretrained StyleGAN network from NVIDIA trained on faces\n",
        "*   A pretrained VGG-16 network, trained on ImageNet\n",
        "\n",
        "After guessing the initial latent codes using the pretrained ResNet, it will run gradient descent to optimize the latent faces!\n",
        "\n",
        "Note that by default, we're optimizing w vectors, not z-vectors!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k1WKZNN3vFVv",
        "colab": {}
      },
      "source": [
        "print(\"aligned_images contains %d images ready for encoding!\" %len(os.listdir('aligned_images/')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TJoVdu6RZ3vY",
        "colab": {}
      },
      "source": [
        "rm -f videos/* # clean up the videos-to-generate folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JaAu5s2Z5Ag2",
        "colab": {}
      },
      "source": [
        "# Set the batch size to the number of images in the aligned_images/ folder\n",
        "# If the results don't look great: Play with the encoding arguments!!!\n",
        "# > 1. More iterations             eg.  1000 (def: 200))\n",
        "# > 2. Decrease the L1 penalty to  eg.   0.1 (def: 0.3))\n",
        "# > 3. Lower initial learning rate eg. 0.005 (def: 0.01) \n",
        "#      Decay_rate (def: 0.8)\n",
        "# > 4. Find out about the other encoding options here: \n",
        "# https://github.com/pbaylies/stylegan-encoder/blob/master/encode_images.py \n",
        "    \n",
        "!python encode_images.py \\\n",
        "--batch_size=2 \\\n",
        "--output_video=True \\\n",
        "--load_resnet='data/finetuned_resnet.h5' \\\n",
        "--lr=0.01 \\\n",
        "--decay_rate=0.8 \\\n",
        "--iterations=100 \\\n",
        "--use_l1_penalty=0.3 \\\n",
        "aligned_images/ generated_images/ latent_representations/\n",
        "\n",
        "print(\"\\n************ Latent code optimization finished! ***************\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zsKCGkhjclX_"
      },
      "source": [
        "#### load the StyleGAN network into memory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n-ErZhh9cqUW",
        "colab": {}
      },
      "source": [
        "import dnnlib, pickle\n",
        "import dnnlib.tflib as tflib\n",
        "tflib.init_tf()\n",
        "synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True), minibatch_size=1)\n",
        "\n",
        "model_dir = 'cache/'\n",
        "model_path = [model_dir+f for f in os.listdir(model_dir) if 'stylegan-ffhq' in f][0]\n",
        "print(\"Loading StyleGAN model from %s...\" %model_path)\n",
        "\n",
        "with dnnlib.util.open_url(model_path) as f:\n",
        "  generator_network, discriminator_network, averaged_generator_network = pickle.load(f)\n",
        "  \n",
        "print(\"StyleGAN loaded & ready for sampling!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9argInqrgIji",
        "colab": {}
      },
      "source": [
        "def generate_images(generator, latent_vector, z = True):\n",
        "    batch_size = latent_vector.shape[0]\n",
        "    \n",
        "    if z: #Start from z: run the full generator network\n",
        "        return generator.run(latent_vector.reshape((batch_size, 512)), None, randomize_noise=False, **synthesis_kwargs)\n",
        "    else: #Start from w: skip the mapping network\n",
        "        return generator.components.synthesis.run(latent_vector.reshape((batch_size, 18, 512)), randomize_noise=False, **synthesis_kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uaSENEp8efOI",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_imgs(model, rows, columns):\n",
        "  for i in range(rows):\n",
        "    f, axarr = plt.subplots(1,columns, figsize = (20,8))\n",
        "    for j in range(columns):\n",
        "      img = generate_images(model, np.random.randn(1,512), z = True)[0]\n",
        "      axarr[j].imshow(img)\n",
        "      axarr[j].axis('off')\n",
        "      axarr[j].set_title('Resolution: %s' %str(img.shape))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g1wKMAcvUPoH"
      },
      "source": [
        "#### show the encoded images\n",
        "\n",
        "If the results don't look great: Play with the encoding arguments!!!\n",
        "> 1. Run the optimization for more iterations (eg 1000)\n",
        "> 2. Decrease the L1 penalty (to eg 0.1)\n",
        "> 3. Try a lower initial learning rate (eg 0.005) or play with the decay_rate\n",
        "> 4. Find out about the other encoding options here: https://github.com/pbaylies/stylegan-encoder/blob/master/encode_images.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uHRNwnSshG_A",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "for f in sorted(os.listdir('latent_representations')):\n",
        "  w = np.load('latent_representations/' + f).reshape((1,18,-1))\n",
        "  img = generate_images(averaged_generator_network, w, z = False)[0]\n",
        "  plt.imshow(img)\n",
        "  plt.axis('off')\n",
        "  plt.title(\"Generated image from %s\" %f)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cJNqedjdi-MZ"
      },
      "source": [
        "#### show the encoded samples side by side with the original ones:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ab7zzXNuJMzJ",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_two_images(img1,img2, img_id, fs = 12):\n",
        "  f, axarr = plt.subplots(1,2, figsize=(fs,fs))\n",
        "  axarr[0].imshow(img1)\n",
        "  axarr[0].title.set_text('Encoded img %d' %img_id)\n",
        "  axarr[1].imshow(img2)\n",
        "  axarr[1].title.set_text('Original img %d' %img_id)\n",
        "  plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
        "  plt.show()\n",
        "\n",
        "def display_sbs(folder1, folder2, res = 256):\n",
        "  if folder1[-1] != '/': folder1 += '/'\n",
        "  if folder2[-1] != '/': folder2 += '/'\n",
        "    \n",
        "  imgs1 = sorted([f for f in os.listdir(folder1) if '.png' in f])\n",
        "  imgs2 = sorted([f for f in os.listdir(folder2) if '.png' in f])\n",
        "  if len(imgs1)!=len(imgs2):\n",
        "    print(\"Found different amount of images in aligned vs raw image directories. That's not supposed to happen...\")\n",
        "  \n",
        "  for i in range(len(imgs1)):\n",
        "    img1 = Image.open(folder1+imgs1[i]).resize((res,res))\n",
        "    img2 = Image.open(folder2+imgs2[i]).resize((res,res))\n",
        "    plot_two_images(img1,img2, i)\n",
        "    print(\"\")\n",
        "     \n",
        "display_sbs('generated_images/', 'aligned_images/', res = 512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y3GK-0POCP52"
      },
      "source": [
        "#### display videos of image generation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-SAf9E65krWQ",
        "colab": {}
      },
      "source": [
        "ls videos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f8T7mlGN3E3r",
        "colab": {}
      },
      "source": [
        "videos_dir = 'videos'  \n",
        "videos_dir_bck = 'videos'  \n",
        "\n",
        "\n",
        "!ls $videos_dir\n",
        "\n",
        "thereisbck = os.path.isdir(videos_dir_bck)\n",
        "print(\"thereisbck %s\" %(thereisbck))\n",
        "\n",
        "if thereisbck == True:\n",
        "  print(\"video folders with first names: %s\" %(videos_dir_bck))\n",
        "else:\n",
        "  print(\"copy to bck\")\n",
        "  !cp -r $videos_dir $videos_dir_bck\n",
        "\n",
        "vids = sorted(os.listdir(videos_dir))\n",
        "print(\"Found %d videos in %s\" %(len(vids), videos_dir))\n",
        "for i, vid_fullname in enumerate(vids):\n",
        "  vid_name = vid_fullname.split('.')[0]\n",
        "  vid_ext = vid_fullname.split('.')[1]\n",
        "  newvid_fullname = 'vid_%02d.%s' %(i, vid_ext)\n",
        "  os.rename(videos_dir + '/' + vid_fullname, videos_dir + '/' + newvid_fullname)\n",
        "!ls $videos_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MtLY79VHlDY6",
        "colab": {}
      },
      "source": [
        "from moviepy.editor import *\n",
        "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
        "from moviepy.Clip import Clip\n",
        "from IPython.display import display\n",
        "\n",
        "videos_dir = 'videos'  \n",
        "vids = sorted(os.listdir(videos_dir))\n",
        "for i, vid in enumerate(vids):\n",
        "  vid_name = videos_dir + '/' + vid\n",
        "  print(\"vid %d : %s\" %(i, vid_name))\n",
        "  clip = VideoFileClip(vid_name)\n",
        "  display(clip.ipython_display(height=512, autoplay=1, loop=1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VFbpOqW5OelA"
      },
      "source": [
        "### set the good images and dump their latent vectors to the root folder on disk \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4GTabUrpOwRR",
        "colab": {}
      },
      "source": [
        "folder = 'latent_representations'\n",
        "\n",
        "good_images = []\n",
        "for i, latents in enumerate(sorted(os.listdir(folder))):\n",
        "  good_images.append(i)\n",
        "      \n",
        "# good_images = [0,1,2,3]  # Uncomment and Change these numbers to pick out latents that worked well (see the image plots)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hKtgwRDPOgrt",
        "colab": {}
      },
      "source": [
        "out_file = '../output_vectors.npy'\n",
        "\n",
        "import numpy as np\n",
        "latents = sorted(os.listdir('latent_representations'))\n",
        "\n",
        "final_w_vectors = []\n",
        "for img_id in good_images:\n",
        "  w = np.load('latent_representations/' + latents[img_id])\n",
        "  final_w_vectors.append(w)\n",
        "\n",
        "final_w_vectors = np.array(final_w_vectors)\n",
        "np.save(out_file, final_w_vectors)\n",
        "print(\"%d latent vectors of shape %s saved to %s!\" %(len(good_images), str(w.shape), out_file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mpbk_0vKgEZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# up to root folder\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bMJGA4K--HCx"
      },
      "source": [
        "# Reset runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mIgmKPwzIlJl",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# os.kill(os.getpid(), 9)\n",
        "\n",
        "from numba import cuda\n",
        "cuda.select_device(0)\n",
        "cuda.close()\n",
        "\n",
        "print(\"cpu_ram_total: %s\" %psutil.virtual_memory().total)\n",
        "print(\"cpu_ram_avail: %s\" %psutil.virtual_memory().available)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKTOpoK2AkTl",
        "colab_type": "text"
      },
      "source": [
        "# Notebook II: navigate through latent space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tWXQFcZn-FzY",
        "colab": {}
      },
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "17dgxmZVdYgm",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.VERSION\n",
        "!nvcc --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6OBitszH_AlI"
      },
      "source": [
        "#### Clone tr1pzz's fork of original ShenYujun's InterFaceGAN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ei2940NwDoHE",
        "colab": {}
      },
      "source": [
        "import os\n",
        "path = 'InterFaceGAN'\n",
        "facegangit = \"https://github.com/tr1pzz/InterFaceGAN.git\"\n",
        "# facegangit = \"https://github.com/ShenYujun/InterFaceGAN.git\"\n",
        "isExist = os.path.exists(path)\n",
        "if not isExist:\n",
        "  print(\"InterFaceGAN does not exist. clone %s\" %facegangit)\n",
        "  !git clone $facegangit\n",
        "else:\n",
        "  print(\"InterFaceGAN already exists. will not clone\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3jimeowup6t4",
        "colab": {}
      },
      "source": [
        "# move latent vectors to gan folder\n",
        "!mv output_vectors.npy InterFaceGAN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LtCgxhF-qWt1",
        "colab": {}
      },
      "source": [
        "cd InterFaceGAN/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KpDtPNTXBA7E"
      },
      "source": [
        "#### Download the pretrained StyleGAN FFHQ network from NVIDIA:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VumYqzzx_V-3",
        "colab": {}
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VXGpXn2rp4VG",
        "colab": {}
      },
      "source": [
        "!mv karras2019stylegan-ffhq-1024x1024.pkl models/pretrain/karras2019stylegan-ffhq-1024x1024.pkl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A-jCeP5FLGKy"
      },
      "source": [
        "#### load the latent space vectors from stylegan\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G107GNIrRCwO",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "final_w_vectors = np.load('output_vectors.npy')\n",
        "\n",
        "print(\"%d latent vectors of shape %s loaded from %s!\" %(final_w_vectors.shape[0], str(final_w_vectors.shape[1:]), 'output_vectors.npy'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BZopDqpOjUqx"
      },
      "source": [
        "#### configure the latent-space interpolation to morph the faces:\n",
        "\n",
        "the InterFaceGAN includes pretrained latent directions (age, eyeglasses, gender, pose, smile). others can be trained. see boundaries at: https://github.com/ShenYujun/InterFaceGAN/tree/master/boundaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "02OJnoKiczjy",
        "colab": {}
      },
      "source": [
        "latent_direction = 'age'     #### Pick one of ['age', 'eyeglasses', 'gender', 'pose', 'smile']\n",
        "morph_strength_start = -3           # Controls how strongly we push the face into a certain latent direction (try 1-5)\n",
        "morph_strength_end = 1           # Controls how strongly we push the face into a certain latent direction (try 1-5)\n",
        "nr_interpolation_steps = 24  # The amount of intermediate steps/frames to render along the interpolation path\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tbiHWVLVSUbY"
      },
      "source": [
        "#### generate the latent interpolation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jjej2hrzsn1y",
        "colab": {}
      },
      "source": [
        "boundary_file = 'stylegan_ffhq_%s_w_boundary.npy' %latent_direction\n",
        "print(\"Dump Latent interpolation to disk!\")\n",
        "resultsPath = \"results/%s\" %latent_direction # eg. results/age\n",
        "!rm -r $resultsPath\n",
        "\n",
        "boundary = \"boundaries/stylegan_ffhq_%s_w_boundary.npy\" %latent_direction\n",
        "startDistance = \"%.2f\" %morph_strength_start\n",
        "endDistance = \"%.2f\" %morph_strength_end\n",
        "steps = \"%d\" %nr_interpolation_steps\n",
        "\n",
        "print(\"resultsPath: %s\" %resultsPath)\n",
        "print(\"latent_direction: %s\" %latent_direction)\n",
        "print(\"boundary: %s\" %boundary)\n",
        "print(\"startDistance: %s\" %startDistance)\n",
        "print(\"endDistance: %s\" %endDistance)\n",
        "print(\"steps: %s\" %steps)\n",
        "\n",
        "\n",
        "!python edit.py \\\n",
        "      -m stylegan_ffhq \\\n",
        "      -b $boundary \\\n",
        "      -s Wp \\\n",
        "      -i 'output_vectors.npy' \\\n",
        "      -o $resultsPath \\\n",
        "      --start_distance $startDistance \\\n",
        "      --end_distance $endDistance \\\n",
        "      --steps=$steps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQQ1H97lN43l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boundary_file = 'stylegan_ffhq_%s_w_boundary.npy' %latent_direction\n",
        "print(\"Dump Latent interpolation to disk!\")\n",
        "resultsPath = \"results/%s\" %latent_direction # eg. results/age\n",
        "!rm -r $resultsPath\n",
        "\n",
        "boundary = \"boundaries/stylegan_ffhq_%s_w_boundary.npy\" %latent_direction\n",
        "startDistance = \"%.2f\" %morph_strength_start\n",
        "endDistance = \"%.2f\" %morph_strength_end\n",
        "steps = \"%d\" %nr_interpolation_steps\n",
        "\n",
        "print(\"resultsPath: %s\" %resultsPath)\n",
        "print(\"latent_direction: %s\" %latent_direction)\n",
        "print(\"boundary: %s\" %boundary)\n",
        "print(\"startDistance: %s\" %startDistance)\n",
        "print(\"endDistance: %s\" %endDistance)\n",
        "print(\"steps: %s\" %steps)\n",
        "\n",
        "\n",
        "!python edit.py \\\n",
        "      -m stylegan_ffhq \\\n",
        "      -b $boundary \\\n",
        "      -s Wp \\\n",
        "      -i 'output_vectors.npy' \\\n",
        "      -o $resultsPath \\\n",
        "      --start_distance $startDistance \\\n",
        "      --end_distance $endDistance \\\n",
        "      --steps=$steps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T42E-Nb5AM2_"
      },
      "source": [
        "#### configure video output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LD0oVlmfATur",
        "colab": {}
      },
      "source": [
        "image_folder = 'results/%s' %latent_direction\n",
        "print (\"images folder %s\" %image_folder)\n",
        "video_fps = 12."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KinkBP0OnGUZ"
      },
      "source": [
        "#### render the videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2pgBNXQ0Tf4k",
        "colab": {}
      },
      "source": [
        "from moviepy.editor import *\n",
        "import cv2\n",
        "\n",
        "out_path = 'output_videos/'\n",
        "\n",
        "images = [img_path for img_path in sorted(os.listdir(image_folder)) if '.jpg' in img_path]\n",
        "os.makedirs(out_path, exist_ok=True)\n",
        "\n",
        "prev_id = None\n",
        "img_sets = []\n",
        "for img_path in images:\n",
        "  img_id = img_path.split('_')[0]\n",
        "  if img_id == prev_id: #append\n",
        "    img_sets[-1].append(img_path)\n",
        "    \n",
        "  else: #start a new img set\n",
        "    img_sets.append([])\n",
        "    img_sets[-1].append(img_path)\n",
        "  prev_id = img_id\n",
        "\n",
        "print(\"Found %d image sets!\\n\" %len(img_sets))\n",
        "if image_folder[-1] != '/':\n",
        "  image_folder += '/'\n",
        "\n",
        "def make_video(images, vid_name):\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    video = cv2.VideoWriter(vid_name, fourcc, video_fps, (1024, 1024))\n",
        "    gen = {}\n",
        "    for img in images:\n",
        "      video.write(img)\n",
        "    video.release()\n",
        "    print('finished '+ vid_name)  \n",
        "    \n",
        "for i in range(len(img_sets)):\n",
        "  print(\"\\nGenerating video %d...\" %i)\n",
        "  set_images = []\n",
        "  vid_name = out_path + 'out_video_%s_%02d.mp4' %(latent_direction,i)\n",
        "  for img_path in img_sets[i]:\n",
        "    set_images.append(cv2.imread(image_folder + img_path))\n",
        "\n",
        "  set_images.extend(reversed(set_images))\n",
        "  make_video(set_images, vid_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gqzyMpDNAf9g"
      },
      "source": [
        "#### display the resulting videos inside this Notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LmRevMq-0lsh",
        "colab": {}
      },
      "source": [
        "vids = sorted([f for f in os.listdir('output_videos')])\n",
        "print (\"vids %s\" %vids)\n",
        "for i, vid_name in enumerate(vids):\n",
        "  vid_path = 'output_videos/%s' %vid_name\n",
        "  print (\"vid_path %s\" %vid_path)\n",
        "  clip = VideoFileClip(vid_path)\n",
        "  display(clip.ipython_display(height=512, autoplay=1, loop=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uEhxBvAR-7y3"
      },
      "source": [
        "#### Some things to try:\n",
        "* blend between two faces by doing a linear interpolation in the latent space\n",
        "* the StyleGAN vector has 18x512 dimensions, each of those 18 going into a different layer of the generator ... take the first 9 from person A and the next 9 from person B\n",
        "(This is why it's called \"Style-GAN\": you can manipulate the style of an image at multiple levels of the Generator!)\n",
        "* interpolate in Z-space rather than in W-space (see InterFaceGan paper & repo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSBb0_8-DiAf",
        "colab_type": "text"
      },
      "source": [
        "#### share in the comments of the vieo https://www.youtube.com/watch?v=dCKbRCUyop8 \n",
        "#### or tag the author on Twitter @xsteenbrugge: https://twitter.com/xsteenbrugge"
      ]
    }
  ]
}