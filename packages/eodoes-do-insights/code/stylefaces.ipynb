{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p1oARVh4UVXz"
   },
   "source": [
    "# Style encoding from Xander Steenbrugge\n",
    "https://www.youtube.com/watch?v=dCKbRCUyop8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GQQLV4xfYAJ"
   },
   "source": [
    "## Part I: Encoding images into StyleGAN's latent space\n",
    "\n",
    "Make sure the Runtime type has GPU acceleration enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "LIEdgUIv4vRR",
    "outputId": "24a46fc7-dec7-4a46-c8e7-8083657df8f2"
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "import os\n",
    "import numpy as np\n",
    "import humanize\n",
    "def printm():\n",
    " process = psutil.Process(os.getpid())\n",
    " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "printm() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "f7kpW_UWVtao",
    "outputId": "d82588e9-4215-48f2-e25d-11af0ab3b543"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "YOd4j-8xbCKV",
    "outputId": "1b2591c5-b318-476d-b0fb-b10b9de368ec"
   },
   "outputs": [],
   "source": [
    "!nvcc --version\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "a8gQ_eCmPFyL",
    "outputId": "1d2532b8-d56b-425f-d569-39dc03e79a72"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DWshsjW7Ri24",
    "outputId": "8af382fa-d550-4f6e-a393-38c5c6b0bc67"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XCR8cEViTR1o"
   },
   "source": [
    "## set globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q78b9yb8TNTW"
   },
   "outputs": [],
   "source": [
    "uploadRawImages = 1\n",
    "takePhotoImages = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RVGS1TnvVd35"
   },
   "source": [
    "### Clone pbaylies' stylegan encoder:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M6-YdNWaTPlq"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BkycNxEeUWBA",
    "outputId": "c88b9324-0f9a-46df-edba-e729f7931c01"
   },
   "outputs": [],
   "source": [
    "path = 'stylegan-encoder'\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "  print(\"stylegan-encoder does not exist. to clone\")\n",
    "  !git clone https://github.com/pbaylies/stylegan-encoder\n",
    "else:\n",
    "  print(\"stylegan-encoder already exists. will not clone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JN15dzgyVg8D"
   },
   "source": [
    "### cd into the repo folder: (only run this cell once or things might get buggy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "F-L8CaC6O6Bv",
    "outputId": "9f72c34a-d5a2-4e8d-e533-2bf5122c0122"
   },
   "outputs": [],
   "source": [
    "cd stylegan-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sv2Pw_1iUKMO"
   },
   "source": [
    "### Let's see the files inside the repo we just cloned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "colab_type": "code",
    "id": "glg1mT2aKizL",
    "outputId": "e9459189-1999-4414-e300-bd7a28a19d16"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gXzIm_TqVk2Q"
   },
   "source": [
    "\n",
    "### create aligned_images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5khz8dizO_JB"
   },
   "outputs": [],
   "source": [
    "mkdir -p aligned_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xIyzoP55S0hA"
   },
   "source": [
    "##create raw_images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vl9qVJrpSyuP"
   },
   "outputs": [],
   "source": [
    "mkdir -p raw_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wEkL_Zqaufcf"
   },
   "source": [
    "# I. Get Images:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wb6eYXL7Pm3S"
   },
   "source": [
    "## Some tips for the images:\n",
    "\n",
    "\n",
    "*   Use HD images (preferably > 1000x1000 pixels)\n",
    "*   Make sure your face is not too small\n",
    "*   Neutral expressions & front facing faces will give better results\n",
    "*   Clear, uniform lighting conditions are also recommened\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qWHBm38POhJ5"
   },
   "source": [
    "## Option 1: Upload Images manually (usually gives the best results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0veUQL2_OoBr"
   },
   "source": [
    "\n",
    "\n",
    "*   Click the '>' icon in the panel on the top left \n",
    "*   Go to the 'Files' tab\n",
    "*   Unfold the stylegan-encoder folder\n",
    "*   Right click the 'stylegan-encoder/raw_images' folder and click \"upload\"\n",
    "*   I'd recommend starting with 3 - 6 different images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nE8Xvb0EUFM5",
    "outputId": "6c649887-b029-4789-8409-e0141a71f479"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "O-XUgE3FTeMK",
    "outputId": "d69d562f-2850-47ca-f1ae-6b23ac2a35cd"
   },
   "outputs": [],
   "source": [
    "if uploadRawImages == 1:\n",
    "  !cd raw_images # will not change cwd\n",
    "  print(\"upload raw images to stylegan-encoder/raw_image\")\n",
    "  from google.colab import files\n",
    "  uploaded = files.upload()\n",
    "  for fn in uploaded.keys():\n",
    "    print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VWLnAIHz7TQm",
    "outputId": "98ee315d-600f-4aa1-f1bd-c854f2abd381"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ToBlvfPgPedc"
   },
   "source": [
    "## Option 2: Take images using your webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZU_R54n2_qYr"
   },
   "outputs": [],
   "source": [
    "if takePhotoImages == 1:\n",
    "  from base64 import b64decode\n",
    "  from IPython.display import HTML, Audio\n",
    "  from google.colab.output import eval_js\n",
    "  from PIL import Image\n",
    "  from datetime import datetime\n",
    "\n",
    "  VIDEO_HTML = \"\"\"\n",
    "  <video autoplay\n",
    "   width=%d height=%d style='cursor: pointer;'></video>\n",
    "  <script>\n",
    "\n",
    "  var video = document.querySelector('video')\n",
    "\n",
    "  navigator.mediaDevices.getUserMedia({ video: true })\n",
    "    .then(stream=> video.srcObject = stream)\n",
    "\n",
    "  var data = new Promise(resolve=>{\n",
    "    video.onclick = ()=>{\n",
    "      var canvas = document.createElement('canvas')\n",
    "      var [w,h] = [video.offsetWidth, video.offsetHeight]\n",
    "      canvas.width = w\n",
    "      canvas.height = h\n",
    "      canvas.getContext('2d')\n",
    "            .drawImage(video, 0, 0, w, h)\n",
    "      video.srcObject.getVideoTracks()[0].stop()\n",
    "      video.replaceWith(canvas)\n",
    "      resolve(canvas.toDataURL('image/jpeg', %f))\n",
    "    }\n",
    "  })\n",
    "  </script>\n",
    "  \"\"\"\n",
    "\n",
    "  def take_photo(quality=1.0, size=(800,600)):\n",
    "    display(HTML(VIDEO_HTML % (size[0],size[1],quality)))\n",
    "    data = eval_js(\"data\")\n",
    "    binary = b64decode(data.split(',')[1])\n",
    "    f = io.BytesIO(binary)\n",
    "    img = np.asarray(Image.open(f))\n",
    "\n",
    "    timestampStr = datetime.now().strftime(\"%d-%b-%Y (%H:%M:%S.%f)\")\n",
    "    filename = 'raw_images/photo_%s.jpeg' %timestampStr\n",
    "    Image.fromarray(img).save(filename)\n",
    "    print('Image captured and saved to %s' %filename)\n",
    "\n",
    "  img = take_photo() # click the image to capture a frame!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7c0sB3grQ0b9"
   },
   "source": [
    "## Let's check the contents of our image folder before we start:\n",
    "#### (You can always manually delete images by right clicking on them in the file tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "colab_type": "code",
    "id": "t0hakluVJXvO",
    "outputId": "cbabc0f7-4d4d-4d52-8131-054b616ba1eb"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "imgs = sorted(os.listdir('raw_images'))\n",
    "\n",
    "print(\"Found %d images in %s\" %(len(imgs), 'raw_images'))\n",
    "if len(imgs) == 0:\n",
    "  print(\"Upload images to the \\\"raw_images\\\" folder!\")\n",
    "else:\n",
    "  print(imgs)\n",
    "\n",
    "for img_path in imgs:\n",
    "  img = Image.open('raw_images/' + img_path)\n",
    "  \n",
    "  w,h = img.size\n",
    "  rescale_ratio = 256 / min(w,h)\n",
    "  img = img.resize((int(rescale_ratio*w),int(rescale_ratio*h)), Image.LANCZOS)\n",
    "  display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4MM8TtbwK5w8"
   },
   "source": [
    "# II. Auto-Align faces:\n",
    "### This script wil:\n",
    "\n",
    "\n",
    "1.   Look for faces in the images\n",
    "2.   Crop out the faces from the images\n",
    "3.   Align the faces (center the nose and make the eyes horizontal)\n",
    "4.   Rescale the resulting images and save them in \"aligned_images\" folder\n",
    "\n",
    "### The cell below takes about a minute to run\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "de-TddqU_dY-",
    "outputId": "d358a97b-977a-49de-f9a8-b2cebbee39ce"
   },
   "outputs": [],
   "source": [
    "!python align_images.py raw_images/ aligned_images/ --output_size=1048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gB8kxWpBRSMA"
   },
   "source": [
    "## Let's take a look at our aligned images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "colab_type": "code",
    "id": "M_Er59x8Mt54",
    "outputId": "1cad6dbe-4be7-4916-e774-0659d36befb0"
   },
   "outputs": [],
   "source": [
    "def display_folder_content(folder, res = 256):\n",
    "  if folder[-1] != '/': folder += '/'\n",
    "  for i, img_path in enumerate(sorted(os.listdir(folder))):\n",
    "    if '.png' in img_path:\n",
    "      display(Image.open(folder+img_path).resize((res,res)), 'img %d: %s' %(i, img_path))\n",
    "      print('\\n')\n",
    "      \n",
    "display_folder_content('aligned_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OaEzcVk7RVjI"
   },
   "source": [
    "# Important, before moving on:\n",
    "### Manually clean the 'aligned_images' directory\n",
    "\n",
    "> ### 1. Manually remove all 'bad' images that are not faces / don't look sharp / clear \n",
    "> #####  (Use the image names from the plots above to guide you)\n",
    "> ### 2. Make sure you don't have too many faces in this folder (8 at most preferably)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0mtyFkhHRMU"
   },
   "source": [
    "### Encoding faces into StyleGAN latent space:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLaBRaNjSsZc"
   },
   "source": [
    "### We'll be using pbaylies' awesome encoder repo (building on original work from Puzer): https://github.com/pbaylies/stylegan-encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmHwHBH8QUc7"
   },
   "source": [
    "## First, let's download a pretrained resnet encoder: (see video for what this does)\n",
    "### --> This model takes an image as input and estimates the corresponding latent code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "DVdh8LIdQVSz",
    "outputId": "6b50b28d-f3c0-4729-a13d-7d216fb68b75"
   },
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=1aT59NFy9-bNyXjDuZOTMl0qX0jmZc6Zb\n",
    "!mkdir -p data\n",
    "!mv finetuned_resnet.h5 data\n",
    "!rm -rf generated_images latent_representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p3Xjrc2hTmMI"
   },
   "source": [
    "# III. The actual encoding process:\n",
    "> #### Play with the encoding params: they have a huge effect on the latent representations & images!\n",
    "> #### Extra encoding options: https://github.com/pbaylies/stylegan-encoder/blob/master/encode_images.py\n",
    "\n",
    "#### Note: This script will also download:\n",
    "\n",
    "\n",
    "*   The pretrained StyleGAN network from NVIDIA trained on faces\n",
    "*   A pretrained VGG-16 network, trained on ImageNet\n",
    "\n",
    "#### After guessing the initial latent codes using the pretrained ResNet, it will run gradient descent to optimize the latent faces!\n",
    "#### Note that by default, we're optimizing w vectors, not z-vectors!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "k1WKZNN3vFVv",
    "outputId": "a711e292-9abe-49ca-ead7-876d89502226"
   },
   "outputs": [],
   "source": [
    "print(\"aligned_images contains %d images ready for encoding!\" %len(os.listdir('aligned_images/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJoVdu6RZ3vY"
   },
   "outputs": [],
   "source": [
    "rm -r videos # remove videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GqiCMtQnZJus"
   },
   "source": [
    "#### For best performance, set the batch_size argument below equal to the number of aligned_images (see previous cell)\n",
    "> Keep batch_size<8 or the GPU might run out of memory (Colab runs on Tesla K80's)\n",
    "\n",
    "### Depending on the settings, the encoding process might take a few minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JaAu5s2Z5Ag2",
    "outputId": "472c1eab-042d-4c5c-82c0-6d20e209a9fb"
   },
   "outputs": [],
   "source": [
    "!python encode_images.py \\\n",
    "--batch_size=2 \\\n",
    "--output_video=True \\\n",
    "--load_resnet='data/finetuned_resnet.h5' \\\n",
    "--lr=0.01 \\\n",
    "--decay_rate=0.8 \\\n",
    "--iterations=200 \\\n",
    "--use_l1_penalty=0.3 aligned_images/ generated_images/ latent_representations/\n",
    "\n",
    "print(\"\\n************ Latent code optimization finished! ***************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zsKCGkhjclX_"
   },
   "source": [
    "## Showtime!\n",
    "### Let's load the StyleGAN network into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "n-ErZhh9cqUW",
    "outputId": "8ce49538-2dba-4ae0-c5b7-04bf1ce8a847"
   },
   "outputs": [],
   "source": [
    "import dnnlib, pickle\n",
    "import dnnlib.tflib as tflib\n",
    "tflib.init_tf()\n",
    "synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True), minibatch_size=1)\n",
    "\n",
    "model_dir = 'cache/'\n",
    "model_path = [model_dir+f for f in os.listdir(model_dir) if 'stylegan-ffhq' in f][0]\n",
    "print(\"Loading StyleGAN model from %s...\" %model_path)\n",
    "\n",
    "with dnnlib.util.open_url(model_path) as f:\n",
    "  generator_network, discriminator_network, averaged_generator_network = pickle.load(f)\n",
    "  \n",
    "print(\"StyleGAN loaded & ready for sampling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9argInqrgIji"
   },
   "outputs": [],
   "source": [
    "def generate_images(generator, latent_vector, z = True):\n",
    "    batch_size = latent_vector.shape[0]\n",
    "    \n",
    "    if z: #Start from z: run the full generator network\n",
    "        return generator.run(latent_vector.reshape((batch_size, 512)), None, randomize_noise=False, **synthesis_kwargs)\n",
    "    else: #Start from w: skip the mapping network\n",
    "        return generator.components.synthesis.run(latent_vector.reshape((batch_size, 18, 512)), randomize_noise=False, **synthesis_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uaSENEp8efOI"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_imgs(model, rows, columns):\n",
    "  for i in range(rows):\n",
    "    f, axarr = plt.subplots(1,columns, figsize = (20,8))\n",
    "    for j in range(columns):\n",
    "      img = generate_images(model, np.random.randn(1,512), z = True)[0]\n",
    "      axarr[j].imshow(img)\n",
    "      axarr[j].axis('off')\n",
    "      axarr[j].set_title('Resolution: %s' %str(img.shape))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mXRzBMf1ckiW"
   },
   "source": [
    "##Let's plot some random StyleGAN samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0humrYHMcjkB",
    "outputId": "48e20267-75f2-40b0-adc8-937e8ce1e81e"
   },
   "outputs": [],
   "source": [
    "plot_imgs(averaged_generator_network, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g1wKMAcvUPoH"
   },
   "source": [
    "# Let's take a look at the results of our encoding:\n",
    "### If the results don't look great: Play with the encoding arguments!!!\n",
    "> 1. Run the optimization for more iterations (eg 1000)\n",
    "> 2. Decrease the L1 penalty (to eg 0.1)\n",
    "> 3. Try a lower initial learning rate (eg 0.005) or play with the decay_rate\n",
    "> 4. Find out about the other encoding options here: https://github.com/pbaylies/stylegan-encoder/blob/master/encode_images.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "uHRNwnSshG_A",
    "outputId": "681a5f02-8e8e-43bd-9498-f0c3787b2b76"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for f in sorted(os.listdir('latent_representations')):\n",
    "  w = np.load('latent_representations/' + f).reshape((1,18,-1))\n",
    "  img = generate_images(averaged_generator_network, w, z = False)[0]\n",
    "  plt.imshow(img)\n",
    "  plt.axis('off')\n",
    "  plt.title(\"Generated image from %s\" %f)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cJNqedjdi-MZ"
   },
   "source": [
    "## Let's compare our encoded samples with the original ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "colab_type": "code",
    "id": "Ab7zzXNuJMzJ",
    "outputId": "168e3aea-7993-47d1-aa92-61c5c2d579c3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_two_images(img1,img2, img_id, fs = 12):\n",
    "  f, axarr = plt.subplots(1,2, figsize=(fs,fs))\n",
    "  axarr[0].imshow(img1)\n",
    "  axarr[0].title.set_text('Encoded img %d' %img_id)\n",
    "  axarr[1].imshow(img2)\n",
    "  axarr[1].title.set_text('Original img %d' %img_id)\n",
    "  plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "  plt.show()\n",
    "\n",
    "def display_sbs(folder1, folder2, res = 256):\n",
    "  if folder1[-1] != '/': folder1 += '/'\n",
    "  if folder2[-1] != '/': folder2 += '/'\n",
    "    \n",
    "  imgs1 = sorted([f for f in os.listdir(folder1) if '.png' in f])\n",
    "  imgs2 = sorted([f for f in os.listdir(folder2) if '.png' in f])\n",
    "  if len(imgs1)!=len(imgs2):\n",
    "    print(\"Found different amount of images in aligned vs raw image directories. That's not supposed to happen...\")\n",
    "  \n",
    "  for i in range(len(imgs1)):\n",
    "    img1 = Image.open(folder1+imgs1[i]).resize((res,res))\n",
    "    img2 = Image.open(folder2+imgs2[i]).resize((res,res))\n",
    "    plot_two_images(img1,img2, i)\n",
    "    print(\"\")\n",
    "     \n",
    "display_sbs('generated_images/', 'aligned_images/', res = 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y3GK-0POCP52"
   },
   "source": [
    "### Note: \n",
    "If you want to watch the whole thing unfold for yourself, you can **download the optimization videos** from the \"videos\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-SAf9E65krWQ",
    "outputId": "4aea731c-c200-44a8-95ae-3edfe1a223ae"
   },
   "outputs": [],
   "source": [
    "ls videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "f8T7mlGN3E3r",
    "outputId": "44b84cf7-f85a-453c-a43c-ec84d8f036c5"
   },
   "outputs": [],
   "source": [
    "videos_dir = 'videos'  \n",
    "videos_dir_bck = 'videos'  \n",
    "\n",
    "\n",
    "!ls $videos_dir\n",
    "\n",
    "thereisbck = os.path.isdir(videos_dir_bck)\n",
    "print(\"thereisbck %s\" %(thereisbck))\n",
    "\n",
    "if thereisbck == True:\n",
    "  print(\"video folders with first names: %s\" %(videos_dir_bck))\n",
    "else:\n",
    "  print(\"copy to bck\")\n",
    "  !cp -r $videos_dir $videos_dir_bck\n",
    "\n",
    "vids = sorted(os.listdir(videos_dir))\n",
    "print(\"Found %d videos in %s\" %(len(vids), videos_dir))\n",
    "for i, vid_fullname in enumerate(vids):\n",
    "  vid_name = vid_fullname.split('.')[0]\n",
    "  vid_ext = vid_fullname.split('.')[1]\n",
    "  newvid_fullname = 'vid_%02d.%s' %(i, vid_ext)\n",
    "  os.rename(videos_dir + '/' + vid_fullname, videos_dir + '/' + newvid_fullname)\n",
    "!ls $videos_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MtLY79VHlDY6",
    "outputId": "8f204be8-4e72-4e5c-e113-bc43323acd6c"
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.Clip import Clip\n",
    "from IPython.display import display\n",
    "\n",
    "videos_dir = 'videos'  \n",
    "vids = sorted(os.listdir(videos_dir))\n",
    "for i, vid in enumerate(vids):\n",
    "  vid_name = videos_dir + '/' + vid\n",
    "  print(\"vid %d : %s\" %(i, vid_name))\n",
    "  clip = VideoFileClip(vid_name)\n",
    "  display(clip.ipython_display(height=512, autoplay=1, loop=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VFbpOqW5OelA"
   },
   "source": [
    "# IV. Set the good images & dump their latent vectors to disk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4GTabUrpOwRR"
   },
   "outputs": [],
   "source": [
    "good_images = []\n",
    "folder = 'latent_representations'\n",
    "for i, latents in enumerate(sorted(os.listdir(folder))):\n",
    "  good_images.append(i)\n",
    "      \n",
    "# good_images = [0,1,2,3]  # Uncomment and Change these numbers to pick out latents that worked well (see the image plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hKtgwRDPOgrt",
    "outputId": "137a97a5-328d-40d4-b4df-b9485b635bf2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "latents = sorted(os.listdir('latent_representations'))\n",
    "\n",
    "out_file = '../output_vectors.npy'\n",
    "\n",
    "final_w_vectors = []\n",
    "for img_id in good_images:\n",
    "  w = np.load('latent_representations/' + latents[img_id])\n",
    "  final_w_vectors.append(w)\n",
    "\n",
    "final_w_vectors = np.array(final_w_vectors)\n",
    "np.save(out_file, final_w_vectors)\n",
    "print(\"%d latent vectors of shape %s saved to %s!\" %(len(good_images), str(w.shape), out_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2t3yvFqMAfoX"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('../output_vectors.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bMJGA4K--HCx"
   },
   "source": [
    "# Notebook II: Playing with Latent Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mIgmKPwzIlJl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def restart_runtime():\n",
    "  os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "colab_type": "code",
    "id": "tWXQFcZn-FzY",
    "outputId": "7333be5f-8af2-4d20-b3b0-5b656e23aee9"
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "17dgxmZVdYgm",
    "outputId": "5eb029dc-56fd-448a-99d3-8c18cc9a152e"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "79zSyWeEKNLz",
    "outputId": "cd4e2ff2-9669-4501-b1fd-4add548dc6a2"
   },
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6OBitszH_AlI"
   },
   "source": [
    "## Clone tr1pzz's fork of original ShenYujun's InterFaceGAN\n",
    "### Original Repo: https://github.com/ShenYujun/InterFaceGAN\n",
    "### Paper: https://arxiv.org/abs/1907.10786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gp-g5awmpMcd",
    "outputId": "3d76cb9c-52cf-422c-b69e-a4930a0de830"
   },
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ei2940NwDoHE",
    "outputId": "a0dcf756-c039-489a-cd1e-150ea8d1e369"
   },
   "outputs": [],
   "source": [
    "path = 'InterFaceGAN'\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "  print(\"InterFaceGAN does not exist. to clone\")\n",
    "  !git clone https://github.com/tr1pzz/InterFaceGAN.git\n",
    "else:\n",
    "  print(\"InterFaceGAN already exists. will not clone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WgEgmzjupiL4",
    "outputId": "0d649f8c-23df-4857-e45f-fc780907faa6"
   },
   "outputs": [],
   "source": [
    "cd InterFaceGAN/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KpDtPNTXBA7E"
   },
   "source": [
    "## Download the pretrained StyleGAN FFHQ network from NVIDIA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "VumYqzzx_V-3",
    "outputId": "a0e456b0-c326-465a-8107-273355859ef3"
   },
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXGpXn2rp4VG"
   },
   "outputs": [],
   "source": [
    "!mv karras2019stylegan-ffhq-1024x1024.pkl models/pretrain/karras2019stylegan-ffhq-1024x1024.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A-jCeP5FLGKy"
   },
   "source": [
    "# I. Let's load the latent space vectors:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-hDjf3jjeaQO",
    "outputId": "658cb218-dd72-4640-a359-49ddc96908cb"
   },
   "outputs": [],
   "source": [
    "!ls ../output_vectors.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "G107GNIrRCwO",
    "outputId": "aa16697d-19eb-4017-b1f7-e3e27847e227"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "final_w_vectors = np.load('../output_vectors.npy')\n",
    "\n",
    "print(\"%d latent vectors of shape %s loaded from %s!\" %(final_w_vectors.shape[0], str(final_w_vectors.shape[1:]), 'output_vectors.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKKHslTK_qXf"
   },
   "source": [
    "## The InterFaceGAN comes with a bunch of pretrained latent directions\n",
    "### (However, you can also train your own!!)\n",
    "### Pick the latent space manipulation we want to use (added it as the -b argument below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kitaBV3ORkMO"
   },
   "source": [
    "Boundaries: https://github.com/ShenYujun/InterFaceGAN/tree/master/boundaries\n",
    "* stylegan_ffhq_age_w_boundary.npy\n",
    "* stylegan_ffhq_eyeglasses_w_boundary.npy\n",
    "* stylegan_ffhq_gender_w_boundary.npy\n",
    "* stylegan_ffhq_pose_w_boundary.npy\n",
    "* stylegan_ffhq_smile_w_boundary.npy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BZopDqpOjUqx"
   },
   "source": [
    "# II. Let's configure our latent-space interpolation\n",
    "### Change the settings below to morph the faces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02OJnoKiczjy"
   },
   "outputs": [],
   "source": [
    "latent_direction = 'age'     #### Pick one of ['age', 'eyeglasses', 'gender', 'pose', 'smile']\n",
    "morph_strength = 3           # Controls how strongly we push the face into a certain latent direction (try 1-5)\n",
    "nr_interpolation_steps = 48  # The amount of intermediate steps/frames to render along the interpolation path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJLg4Px8_hvG"
   },
   "source": [
    "# III. Run the latent space manipulation & generate images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "RDksv9CdjrB3",
    "outputId": "d87839f1-0a8f-4c77-ad09-fc42359d782c"
   },
   "outputs": [],
   "source": [
    "boundary_file = 'stylegan_ffhq_%s_w_boundary.npy' %latent_direction\n",
    "\n",
    "print(\"Ready to start manipulating faces in the ** %s ** direction!\" %latent_direction)\n",
    "print(\"Interpolation from %d to %d with %d intermediate frames.\" %(-morph_strength, morph_strength, nr_interpolation_steps))\n",
    "print(\"\\nLoading latent directions from %s\" %boundary_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tbiHWVLVSUbY"
   },
   "source": [
    "## Ready? Set, Go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "8-QG5vukdX0j",
    "outputId": "eac7d16d-1cf0-4981-83a5-932ce236515e"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "return_code = subprocess.call(\"rm -r results/%s\" %latent_direction, shell=True)\n",
    "\n",
    "run_command = \"python edit.py \\\n",
    "      -m stylegan_ffhq \\\n",
    "      -b boundaries/stylegan_ffhq_%s_w_boundary.npy \\\n",
    "      -s Wp \\\n",
    "      -i '../output_vectors.npy' \\\n",
    "      -o results/%s \\\n",
    "      --start_distance %.2f \\\n",
    "      --end_distance %.2f \\\n",
    "      --steps=%d\" %(latent_direction, latent_direction, -morph_strength, morph_strength, nr_interpolation_steps)\n",
    "\n",
    "\n",
    "print(\"Running latent interpolations... This should not take longer than ~1 minute\")\n",
    "print(\"Running: %s\" %run_command)\n",
    "return_code = subprocess.call(run_command, shell=True)\n",
    "\n",
    "if not return_code:\n",
    "  print(\"Latent interpolation successfully dumped to disk!\")\n",
    "else:\n",
    "  print(\"Something went wrong, try re-executing this cell...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zeL-0qjuGGr2",
    "outputId": "f1579ccb-d89a-427f-c8bb-1f9b42f5ca51"
   },
   "outputs": [],
   "source": [
    "# cd /content/InterFaceGAN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "Jjej2hrzsn1y",
    "outputId": "41e9cd24-5c97-4eb5-9918-0a93cdafa748"
   },
   "outputs": [],
   "source": [
    "\n",
    "!rm -rf results/age\n",
    "!python edit.py \\\n",
    "  -m stylegan_ffhq \\\n",
    "  -b boundaries/stylegan_ffhq_age_w_boundary.npy \\\n",
    "  -s Wp \\\n",
    "  -i '../output_vectors.npy' \\\n",
    "  -o results/age \\\n",
    "  --start_distance -3.0 \\\n",
    "  --end_distance 3.0 \\\n",
    "  --steps=48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T42E-Nb5AM2_"
   },
   "source": [
    "# IV. Finally, turn the results into pretty movies!\n",
    "Adjust which video to render & at what framerate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LD0oVlmfATur"
   },
   "outputs": [],
   "source": [
    "image_folder = 'results/%s' %latent_direction\n",
    "video_fps = 12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KinkBP0OnGUZ"
   },
   "source": [
    "### Render the videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "2pgBNXQ0Tf4k",
    "outputId": "7b51b5c3-2542-42b5-fee8-df6637cbfd1a"
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "import cv2\n",
    "\n",
    "out_path = 'output_videos/'\n",
    "\n",
    "images = [img_path for img_path in sorted(os.listdir(image_folder)) if '.jpg' in img_path]\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "prev_id = None\n",
    "img_sets = []\n",
    "for img_path in images:\n",
    "  img_id = img_path.split('_')[0]\n",
    "  if img_id == prev_id: #append\n",
    "    img_sets[-1].append(img_path)\n",
    "    \n",
    "  else: #start a new img set\n",
    "    img_sets.append([])\n",
    "    img_sets[-1].append(img_path)\n",
    "  prev_id = img_id\n",
    "\n",
    "print(\"Found %d image sets!\\n\" %len(img_sets))\n",
    "if image_folder[-1] != '/':\n",
    "  image_folder += '/'\n",
    "\n",
    "def make_video(images, vid_name):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(vid_name, fourcc, video_fps, (1024, 1024))\n",
    "    gen = {}\n",
    "    for img in images:\n",
    "      video.write(img)\n",
    "    video.release()\n",
    "    print('finished '+ vid_name)\n",
    "    \n",
    "    \n",
    "for i in range(len(img_sets)):\n",
    "  print(\"\\nGenerating video %d...\" %i)\n",
    "  set_images = []\n",
    "  vid_name = out_path + 'out_video_%s_%02d.mp4' %(latent_direction,i)\n",
    "  for img_path in img_sets[i]:\n",
    "    set_images.append(cv2.imread(image_folder + img_path))\n",
    "\n",
    "  set_images.extend(reversed(set_images))\n",
    "  make_video(set_images, vid_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gqzyMpDNAf9g"
   },
   "source": [
    "## Visualise the resulting videos inside this Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "colab_type": "code",
    "id": "6kHw182YT_v6",
    "outputId": "f031a545-a792-4451-d42b-3b0d2731e667"
   },
   "outputs": [],
   "source": [
    "video_file_to_show = 0\n",
    "\n",
    "clip = VideoFileClip('output_videos/out_video_%s_%02d.mp4' %(latent_direction, video_file_to_show))\n",
    "clip.ipython_display(height=512, autoplay=1, loop=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "colab_type": "code",
    "id": "3jztOE_tH7fR",
    "outputId": "cf513377-0ab5-472f-fba0-5865ad3f004c"
   },
   "outputs": [],
   "source": [
    "video_file_to_show = 1\n",
    "\n",
    "clip = VideoFileClip('output_videos/out_video_%s_%02d.mp4' %(latent_direction, video_file_to_show))\n",
    "clip.ipython_display(height=512, autoplay=1, loop=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEhxBvAR-7y3"
   },
   "source": [
    "# V. Your turn to experiment\n",
    "\n",
    "## You now have all the tools to start exploring the latent Space of StyleGAN: HAVE FUN!\n",
    "### StyleGAN paper link: https://arxiv.org/abs/1812.04948\n",
    "\n",
    "### Some things you could try:\n",
    "* You can blend between two faces by doing a linear interpolation in the latent space: very cool!\n",
    "*   The StyleGAN vector has 18x512 dimensions, each of those 18 going into a different layer of the generator...\n",
    "*   You could eg take the first 9 from person A and the next 9 from person B\n",
    "*   This is why it's called \"Style-GAN\": you can manipulate the style of an image at multiple levels of the Generator!\n",
    "*   Try interpolating in Z-space rather than in W-space (see InterFaceGan paper & repo)\n",
    "* Have Fun!!\n",
    "# Find something cool you wanna share? \n",
    "## ---> Tag me on Twitter @xsteenbrugge: https://twitter.com/xsteenbrugge\n",
    "## ---> Or simply share it in the comments on YouTube!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stylefaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
